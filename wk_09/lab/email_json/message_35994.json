{"category": "ham", "to_address": "\"Allison Randal\" <allison@perl.org>", "from_address": "\"Mike Mattie\" <codermattie@gmail.com>", "subject": "Re: [RFC] extension guessing, functionally better loader behavior -> working install target", "body": "Here is the first part of my response. I have dropped the parts\nabout re-factoring and the library.paths parts so we can get\non the same page design wise.\n\nHere goes ....\n\n> I wanted to reply to this before you left on vacation, but Thunderbird\n> crashed taking several unfinished replies with it. (Fresh install, which\n> I hadn't yet configured to automatically save drafts.)\n\n> So, the abbreviated version...\n\nno problem. Right now I am really hobbled with the gmail interface. This\ncoming Saturday I will be back in the saddle with all my files and a real\nmail client.\n\n>> Mike Mattie wrote:\n>> Hello,\n>>\n>> I have been working on implementing extension guessing consistently\nin parrot.\n>> These changes make parrot much more usable, robust, flexible, and\nmaintainable.\n>>\n>> Usable:\n>>\n>> the current parrot implementation requires the extension to be\nspecified. First\n>> what is a extension ? An extension is just a few extra characters tacked on\n>> to a path. All things being right an extension implies a file format.\n>>\n>> In parrot however a file extension is much more. It indicates which stage\n>> of compilation for a module. A module may have multiple stages cached on\n>> disk.\n>>\n>> foo.pir  <- source\n>> foo.pbc  <- bytecode compiled\n>>\n>> The parrot implementation is completely backwards in that the user of\n>> module \"foo\" cannot simply use \"foo\". The user has to explicitly hardwire\n>> which stage of compilation they want along with the module name itself.\n>>\n>> In using parrot there is no good reason for the compilation stage to\n>> matter. (I know about the jit issues on web-servers, it is not relevant).\n>>\n>> In fact having this information \"filter-down\" from the request to load\n>> a module has broken the install target. There are several cases where\n>> someone does \".load_bytecode \"foo.pir\"\" because in the working-copy\n>> they have both foo.pbc and foo.pir. In the install tree only\n>> foo.pbc is installed.\n\n> This can be solved by simply referencing the .pbc file and building the\n> PBC in the make process for a particular subsystem. Which is only to say\n> that automatic extension selection is an optional refinement, not a core\n> requirement.\n\nFor perl5 this will be a requirement. In fact I think this is where\ncommunication of the design is breaking down (my fault).\n\nWhen I set out to solve this problem I did not want to build a crutch\nto hop over the problem I faced personally ; my proposal is a very\ngeneral solution that I hope encompasses the entire spectrum of\nlanguages that parrot will support in the future. I hope that this\nwill result in substantial forward progress, and be in concordance\nwith the theme of parrot as a general solution for languages.\n\nWhen I expanded my problem domain I overloaded the topic. I should\nhave been more clear before , but this discussion will hammer out the\nscope of the proposal.\n\nWhen it comes to loading source code for interpretation of any sort\nthere are common issues: security, OS optimization, well\nunderstood/transparent search behavior, and configuration.\n\nFor security/optimization platforms have similar solutions with\nslightly different flags/calls etc.  The OS optimization needs to\nhappen in C (open flags), and security (open flags, search algorithm,\ninput validation) needs to be implemented in one place. Verification\nby review is hard enough without having to search all over the source\ntree in a variety of languages (C/PIR mix would be bad) to comprehend\nthe implementation. This leads directly into fragmentation.\n\nWhen more languages are implemented with 100% compatability with the\noriginal platforms that the process for locating source files and\nloading them can become fragemented - losing the essential sense of\nparrot \"cohesiveness\".\n\nThis is natural because programmers tend to scan API documentation and\nsource code looking for what they need but do not want to implement.\nLooking at the API for what it is in terms of an abstraction and\namending both their implementation plan and the API itself is far more\nexhausting.\n\nI think the implementation of dynext.c supports this. The code is\nalmost a complete duplication of the primary search loop in\nlibrary.c. The fundamental algorithm both share is combinitorial ;\nwhich I have hoisted and named properly (path_concat_permutations)\nin my proposed library.c implementation (2cnd posting).\n\nThis tendancy towards divergance regardless of motive and the hassle\nit causes is the reason the linux kernel has resisted what they\ndescribe as the \"balkanization\" of the scheduler implementation. This\nis parrot, not Linux but the design principle both valuable, and\napplicable here IMHO. When configuration is brought into the picture\nthis balkanization has real problem potential.\n\nI Think of a common parrot behavior for languages on a VM level as a\n\"look and feel\" issue as well. This is addressed in the new API by the\nsearch trace diagnostic for when the search fails. When all of the\nrelated opcodes use this API, and the diverse languages supported by\nparrot rely on these opcodes parrot centric expectations of behavior\nfor all languages is acheivable in the loading part of a language\nimplementation.\n\n>> So parrot is not able to load code that exists on disk, because parrot\n>> must be explicitly told the exact compilation stage along with the\n>> module, and some compilation stages aren't always useful (intermediate)\n>> or available.\n>>\n>> Two behavioral rules can be formulated to solve this problem:\n>>\n>> Rule 1. When a user requests a module, parrot will load that module using\n>>         whatever format/loader is available. (dlopen, bytecode\nloaders, compilers)\n>>\n>> Rule 2. When a module is requested , for performance the most compiled form\n>>         of that module will be chosen.\n>>\n>>    This is in fact the behavior of perl5 , and I think it should be\n>>    the behavior of perl6. In fact in discussing this on #perl6 someone\n>>    mentioned that there is already perl5 code that relies on this\nbehavior (strange?).\n\n> My take on this is that we should have two opcodes. One that tries to\n> work out the extension for you, and one that is quite literal-minded.\n> When the \"smart loader\" isn't sufficiently smart, the code can fall back\n> to the literal-minded loader.\n\nAll of my committed/proposed changes have tried the \"literal\" version\n*first* , then tried extension guessing as a fallback. This is more\nreliable since the code can over-ride the heuristic approach when\nnecessary , which may not possible with the \"fall-back to literal\"\nbehavior described above. Bad heuristics that prevent a literal input\nfrom working are a most frustrating software behavior.\n\nThe \"literal first\" approach also preserves existing behavior\nperfectly and is the reason why my changes AFAIK have not broken the\nparrot tree. I am politely adamant on this particular point.\n\n> For the sake of sane migration,\n> load_bytecode should continue to work as it always has, and we come up\n> with a new name for the new opcode. (load_bytecode is a misleading name\n> anyway.)\n\n.load_bytecode: I am not talking about changing the behavior of this\nop-code at all for existing code. In fact much of the confusion\nprobably stems from the strong desire of mine to attempting to preserve\nboth existing behavior of this opcode and developer habits ; except the\nPARROT_PREFER_SOURCE part.\n\nThat's ok because .load_bytecode is the first user for the new version\nof this function. If it can't support *all* the bytecodes that\nimplement object-file search-spaces by searching of a list of\ndirectories then it's broken IMHO and I need to fix it.\n\nEventually I would love to see load_bytecode narrowed in scope or\nremoved ; it is horribly overloaded. I hope that my new implementation\nof Parrot_locate_runtime_str will make this easier by moving a well\nabstracted part of the problem out of one op into a routine that is\nmore easily shared by multiple ops.\n\n>> Rule 3:  PARROT_PREFER_SOURCE when this environment variable is\nexported parrot\n>>          will reverse it's normal preference for low-level compiled\nforms , and\n>>          prefer high level source forms.\n\n> An environment variable should not be used to select the behavior of\n> Parrot opcodes. If both behaviors are useful, then provide both as\n> separate opcodes.\n\n.load_bytecode has been influenced by an environment variable, and has\nfor ages: PARROT_RUNTIME. I am raising it as a design issue and\nproperly documenting it. I do not want lapse into a nerdy pendantic\nand obtuse response so I will assume you mean \"no new environment\nvariable influences. PERL5LIB and friends is on the horizon though.\n\nThe point of PARROT_PREFER_SOURCE was simply to eliminate the\nobjections that stemmed from people who did not want to run make clean\nim-between revisions of the code. I tried to make something useful out\nof it instead of immediately rejecting those concerns.\n\nI think this case is situation where the user may want to change the\nbehavior without re-compiling code: transiently , permenently, and by\n\"session\". Environment variables are process inherited and are AFAIK\nthe only cross-platform configuration mechanism with this kind of\nflexibility. I can start two shells , set the defaults in a shell\nconfiguration file such as \".profile\" , change it in one shell\ntemporarily with a single command issued once , and discard that\nchange by simply exiting the shell. This is do-able on windows as\nwell, but not as common a practice due to the weak CLI environment.\n\nI think PARROT_PREFER_SOURCE is very nice and useful by the Larry Wall\nlaziness principle but I will drop it if no one else sees sufficient\nbenifit.\n\n>> Flexible:\n>>\n>> I am working on making parrot more flexible by allowing languages/compilers\n>> to have a \"namespace\" within the loader.\n>>\n>> Please do *not* tie this part to the rest. It only exists in my working-tree\n>> and is easily ripped out of the rest of the proposal.\n>>\n>> This is a more speculative feature, but I think a good one. While reading\n>> pdd21 concerning HLL name-spaces and interoperability I decided to try\n>> the time-machine experiment.\n>>\n>> Fast-fowarding to a future where parrot rules the earth I see parrot\n>> having byte-code loaders for a range of languages: java, CLR, python,\n>> perl5, perl6, etc.\n>>\n>> Each language has it's own runtime, a set of libraries, architecture\n>> objects (machine-code) , bytecode objects, and source files. Parrot\n>> can interpret all of these but there is no reason to re-implement them\n>> all from source.\n>>\n>> If each language could have a \"namespace\" within the loader then the\n>> java runtime distributed by Sun/whoever could be used by parrot\n>> without any collisions for the wheels that everyone has to re-invent\n>> like string,file,io etc.\n\n> I halfway get the impression that you're working backwards here. You\n> want to make extensions irrelevant, but once you do that, you need some\n> way to distinguish between different languages, so you add the\n> distinctions back in as directory hierarchy.\n\nExtensions: they are an optimization hint/feature\n\nI never take the extension to be anything but a optimization hint.\nWhat a file contains should be determined by inspection. That being\nsaid I think parrot can be very slick here.\n\nI was specifically inspired by \"pheme.g\": the PGE grammar for pheme. I\nthought to myself why does the build system have to generate all this\nintermediate junk on disk ? It clutters the build and the tree on disk\nbecause parrot needs hand-holding at the build-system level to walk it\nthrough the translation phases ; completely ignoring the HLL\ninfrastructure. Why can't parrot just see a \".g\", assume until\nsomething goes wrong that it's a grammar, use the HLLcompiler\ninfrastructure to run through the translation phases , and then link\nit in ?\n\nIf parrot can do that , then caching the translation phases ie\ncompilation should just be a matter of stopping translation at a\nspecific phase and outputting to disk with the right extension. When\nthe install is performed the most compiled version is copied, and\n\"pheme.g\" is left in the source tree.\n\nWith the whole extension guessing thing finding the \"preferred\nextension\" is finding *the optimal first phase of translation*. The\nHLLcompiler infrastructure is primed by that vital information to\nproduce an executable form.\n\nFor example: Say I make a directory for each of the major phases of\ntransation, parse, OST etc. In each directory I have the .g file,\nor the .tge file. I have a \"super-op\" called \".load_it\" . In the\ncore pheme I have something like \".load_it grammar/pheme\".\n\nWhen I am working on the grammar in the source tree I can change the\ngrammar file and re-run the interpreter core without re-compiling the\ninterpreter core - it will run through all the translation phases\nevery time I run it. This is nice for development.\n\nWhen I am finished developing and do the build/install it will pick up\nthe compiled version in the install tree and use that, which is\nperformance optimal for a system-wide install.\n\nThis one implementation of Parrot_locate_runtime_file_str does the\ndiscovery of what's available, aka finding the available object-file\nforms and selecting the most optimal starting phase of the\ntranslation to an internally executable form.\n\nPer-language search space:\n\nIf parrot is going to become \"one VM to rule them all\" , then it will\nneed \"one loader to load them all\". Parrot_locate_runtime_file_str is\nnot the loader - it does the discovery of what is available to load. In\nthat way it is \"one search implementation to discover them all\".\n\nI want to support *all* languages with Parrot_locate_runtime_file_str\n- \"Do it in one place\". Python has it's own tree of modules\ndistributed along with \"/usr/bin/python\". So does every other\nnon-trivial language with an extensive library.\n\nThe ideal future I am envisioning uses parrot as a \"drop in replacement\"\nfor the interpreter, while using the existing, even compiled libraries\nfor those languages. That way I don't have to keep current on how the\nsame issues are solved in different VM's. I can focus on one VM: parrot,\nand see the fixes and features propogated through all the languages\nI use on a regular basis.\n\nExamples: PERL5LIB , PYTHONLIB, ELISPLIB - they are all search spaces\nfor specific languages. language interoptability doesn't happen until\nthe loader can function correctly as defined by an individual language\n; what is loaded can then be intergrated at a calling convention\nlevel.\n\n> There is some provision to specify a custom library that is loaded when\n> the HLL is selected in the second argument to .HLL. It's limited, and\n> not really used AFAIK.\n\nI am not aware of what you are talking about with the custom library.\nI skimmed over it ;  I freely admit that I do it too :) .\n\n>> Rule: when a loader namespace for a language has not been defined\n>>       the default namespace \"parrot\" is used. If a lookup fails\n>>       within the parrot namespace the load fails.\n\n> What's the distinction between loader namespace and Parrot namespace?\n\nCalling it a loader name-space is a garbling of terms that I will\nhopefully correct in a very precise way . Having the concept of\nloaders disjunct to translation phases is a vital aquiescence to the\ncurrent practice of a single module, say sha1 implemented at both a\nlow-level and a high level or C/byte-code.\n\nBefore the relationship between a loader and a language is established\nthe class of loaders and their kind must be established.\n\nfundamentum divisionis: loaders are a translation phase where linking\ncan be performed with minimal residual analysis of the higher level\nforms.\n\nIn simplest terms a loader is a translation phase where the objects\nare functionally both interchange-able and opaque to the loader.\n\nTwo examples:\n\nThe C pre-processor forms a translation unit for compilation via the\n#include directive. This recursive combination of seperate files into\na single stream for syntatic anaylsis is done with only the lexing\nnecessary to identify CPP directives and expand them.\n\nOn the level of the link-loader the relocation fix-ups are performed\nwithout any knowledge of the original source except the residual\nsymbol export/import tables. Only the addresses of load/store/branch\ninstructions are significant, not what the instruction semantics.\n\nMy four kinds of loader:\n\nOS (was ARCH),   : the operating system loader\nBYTECODE         : byte-code object-files for various VM's such as python,java\nINCLUDE          : .PAST level include processing\nSOURCE           : triggers imcc/HLLCompiler driven translation\n\nThis is not logically exhaustive - rather de-facto useful.\n\nThe OS kind is distinct because it is largely implemented external to\nparrot.\n\nThe BYTECODE kind is distinct because the translation to a\ninternally executable form is based on a regular input format,\nhence byte-code ; contrast with SOURCE.\n\nThe INCLUDE kind is distinct because the processing is deferred to\npost-compilation (ie SOURCE) with parrot, and limited to imperative\nstyle macro language, and .include directive processing.\n\nThe SOURCE kind is distinct because it triggers syntax driven context\nfree grammar translation via HLLCompiler? -> imcc -> bytecode.\n\nthe old enum_runtime_ft was a ad-hoc division of object/source file\ntypes , with a bit-mask union classification as OS | SOURCE in the svn\nHEAD version of library.c .\n\nThe analysis above is more clean and useful on a logical level and\nmore precisely defined IMHO. I hope the application of logical\nvocabulary will help clarify rather than obscure the proposal.\n\nReturning to the relationship between loader and language they\nare disjunct because the language uses loaders as containers and\na library module as a whole can be implemented at different levels\nfor a variety of reasons such as performance , access to C level\nAPI's, and the deferring of CPP style macro processing.\n\nEach loader has it's own search-space. This is because the operating\nsystem shared objects can and sometimes should be stored in trees\nseperate from byte-code and source objects. Forcing a single\nsearch-space with a common tree root for seperate object-file types\ncan limit privelage seperation at the operating system level. Sets\nof extensions are specific to a kind of loader.\n\nThe order in which loaders are tried is important. For the sha1\nexample the OS level or C implementation needs to be loaded\nbefore the bytecode level NCI wrappers are loaded. Without the\ndistinction between loaders in the API, and with a first match\nsearch the byte-code part of the library module would not be\nreachable.\n\nThis is realized in the HEAD version of library.c with the seperate\ncode paths depending on the classification OS | SOURCE . My goal\nwas not to remove this , rather to clean it up.\n\nWith the my new implementation of library.{ch} the kinds of loaders\nare general with well defined distinctions. It is possible for both\ndynext and .load_bytecode to use a well insulated\nParrot_locate_runtime_file_str simply by passing an appropriate mask.\n\n>> RFC: I noticed compreg, and quickly scanned through HLLCompiler.\n>>      compiler implies either a translation stage, a sequence of\n>>      translation stages, or a language.\n>>\n>>      Has the meanings been refined architecturally somewhere ?\n>>\n>> Basically the lib_paths global which is currently built like this\n>>\n>> fixed-array[\n>>   paths,      -> resizable array of strings\n>>   extensions, -> resizable array of strings (note how parrot\nalready implements extension guessing)\n>> ]\n>>\n>> becomes this:\n>>\n>> hash keyed by namespace {\n>>\n>>   parrot -> fixed array of loaders [\n>>      ARCH     /*dlopen loader*/       -> [ ... ]\n>>      BYTECODE /* bytecode loaders */  -> [ ... ]\n>>      SOURCE   /* source compilers */  -> fixed array [\n>>                                          SEARCH_PATH  -> resizable\narray of strings\n>>                                          SEARCH_EXT   -> resizable\narray of strings\n>>   ]\n>> }\n>>\n>> With this new structure parrot has enough flexibility that it can\nconstruct a search space\n>> for any language distribution, and can use them all within the same\nparrot instance without\n>> collisions in the search space between languages.\n\n> This doesn't quite work because you have to be able to load one\n> language's libraries from another language. So, you need to be able to\n> load Python's Mail.Filter and Perl's Mail::Filter (fictional examples)\n> at the same time and use them both within the same program.\n\nhash keyed by namespace -> hash keyed by language\n\nyou did not understand what I meant by \"hash keyed by namespace\" I\nthink. I should not use name-space anymore leaving that to the\npdd21 scope issues - my blunder.\n\nI am renaming the argument: STRING* hll -> STRING* language\nso things will not be so confused anymore.\n\nBut with that example you understand why I want a \"per language\nsearch-space\". Hopefuly we are on the same page now.\n\nThe current implementation supports loading them both, that is a\nprimary goal. Using them both at the same time is a namespace issue\naddressed by pdd21 which is far beyond the scope of the loader.\n\nAnother point of confusion is that I had a hard time finding where\nparrot encapsulated the concept of a \"language\". When looking I found\nHLLCompiler which seemed to define a language as a sequence of\ntranslation phases. This is the most useful definition of a language\nfrom the perspective of parrot as far as I can see. At this moment\nfor me HLL = language.\n\nWhat I want to do is have Parrot_locate_runtime_file_str look\nby object_name, by language, and return what is found within\nthe masked loaders.\n\nThat way you can search for a object, in the python language, first by\nshared objects, then by bytecode objects etc. Having a mask for the\nloaders also allows the loading to be split or combined by opcodes at\na higher level of design ; a level that I am not informed to comment\non yet.\n\nWhat I really need to know is how to translate this \"language\" string\ninto a value that will key the translation/loading machinery for\nparrot. All of the SOURCE level loading should be a sequence of translation\nphases starting with the best available object-file form and ending with\nimcc.\n\n> The directories on disk correspond to the Parrot namespace of the\n> libraries as a convention. You could potentially optimize the loading\n> operation by having a load of a Python module only search the Python HLL\n> directory. But, a user-defined module might not follow the convention.\n\nThe fact that a user defined module may not follow the convention is\nnot a problem. With my search algorithm the standard library locations\nwill be searched first so that trusted implementations are always\npreferred.  If nothing is found in the standard library locations the\nobject_name is then tried as a path relative to the current working\ndirectory. I have mentioned things like PERL5LIB. I can easily\nimplement that sort of thing but that is not integral to the core\ndesign, merely a mechanism to extend the search-space for a particular\nlanguage. Considering parrot's current limitations I don't think this\nis an immediate priority if the design is okay.\n\n> Similarly, there is a convention (not entirely consistent) that foo.pbc\n> is the compiled form of foo.pir, but that's not always the case, and\n> certainly not required.\n\nI agree, that is why I am firm on extensions being an optimization\nhint.  In particular the \"use v6;\" is always present in my\nconsideration of how loading needs to be designed and implemented.\n\n>> It could also be used to implement binary compatibility. If\n\"parrot\" is versioned , say\n>> as \"parrot-pre\" \"parrot1\" etc then the loader could support\nselecting a compatible version\n>> of multiple runtime installs.\n\n>What you haven't addressed (and what I consider the most important\n>problem to solve for library loading), is a mechanism for extending\n>Parrot's search path.\n\nI think I have extended it quite far :) Joking aside you are right\nif you are talking about a .pir wrappers to manipulate the search-space\ndata structures. Again this is not essential to the core-design and\ncan be added after a working concencus is reached.\n\nIf you are talking about supporting multiple languages This is why\nI want:\n\n* per language search spaces , was STRING* hll, now STRING* language to\n  clear up the confusion.\n\n* extension guessing ( doesn't matter what language provides the\nfunctions anymore\n                       unless you care. but that is handled at a\nhigher level, at\n                       some point it needs to be explicit, and it is for\n                       Parrot_locate_runtime_file_str )\n\n* integrate with HLLCompiler infrastructure = intergrate with whatever\n  encapsulates the machinery for a language.\n\n> If that were defined, then versioning would be a simple matter of\n> selecting an appropriate search path.\n\nlets call it search-space , and per-language search space so I can\nstop confusing you :) Versioning in the language key is simply a cheap\nside-benefit I thought of.\n\n>> Maintainability:\n>>\n>> This issue will get a bit more involved. the parrot loader is very\nalpha, aka put\n>> together early in the development process. It let people explore\nthe rest of the design\n>> space but a refactor is apparent throughout the code and API.\n\n> This section is a mixture of code refactor ideas and architecture ideas.\n> Would be simpler to process the two separately, but I'll take a stab.\n\n- Show quoted text -\n\nI think we need to first get on the same page by agreeing on terms\nbefore drilling down much further. I apologize for the instances where\nI have confused you since we are clearly articulating the same goals,\nbut not communicating in architecture terms clearly.\n\nIt would really help if there was a place in parrot that encapsulated\nthe entire scope of a language. I discovered .compreg as the closest\nthing I could find to something like that. I also assumed pdd21 was\nwhere I would find the architecture of that encapsulation.\n\nI also wonder if you had the time to look at the second draft of\nlibrary.c . I noticed that you are very familiar with the current\nimplementation. As far as my new implementation I don't think\nyou had time to review the code yet.\n\nI make a particular point of writing code that is readable. I value\nhighly a discussion at the design level, but if the code is not the\noptimal way to understand the design then I am disappointed in how I\nwrote the code. I consider a critique of the code transparency to be\nas important as the design. In particular the \"tagging\" of where the\nsteps of the algorithm is implemented was an attempt to make review\neasier.\n\nThere are parts of the code that I can now re-factor with clarity\nusing a more consistent definition of terms. I will do that within the\nnext couple of days. This response should be enough to ponder for a bit.\n\nI hope at the least that you see that I am working on the general\nloading libraries for multiple languages problem, and that I have a\ndesign that is being refined by this process towards a good\nimplementation.\n\n"}