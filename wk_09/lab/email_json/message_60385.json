{"category": "ham", "to_address": "R-Help <r-help@stat.math.ethz.ch>", "from_address": "\"James R. Graham\" <jamesrgraham@mac.com>", "subject": "[R] Question about PCA with prcomp", "body": "Hello All,\n\nThe basic premise of what I want to do is the following:\n\nI have 20 \"entities\" for which I have ~500 measurements each. So, I  \nhave a matrix of 20 rows by ~500 columns.\n\nThe 20 entities fall into two classes: \"good\" and \"bad.\"\n\nI eventually would like to derive a model that would then be able to  \nclassify new entities as being in \"good territory\" or \"bad territory\"  \nbased upon my existing data set.\n\nI know that not all ~500 measurements are meaningful, so I thought  \nthe best place to begin would be to do a PCA in order to reduce the  \namount of data with which I have to work.\n\nI did this using the prcomp function and found that nearly 90% of the  \nvariance in the data is explained by PC1 and 2.\n\nSo far, so good.\n\nI would now like to find out which of the original ~500 measurements  \ncontribute to PC1 and 2 and by how much.\n\nAny tips would be greatly appreciated! And apologies in advance if  \nthis turns out to be an idiotic question.\n\n\njames\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}