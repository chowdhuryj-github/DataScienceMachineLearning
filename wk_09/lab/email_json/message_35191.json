{"category": "ham", "to_address": "Bert Gunter <gunter.berton@gene.com>", "from_address": "John Christie <jc@or.psychology.dal.ca>", "subject": "Re: [R] repeated measures regression", "body": "Hmmm, been away and got this...  I appreciate the effort but there  \nwasn't anything, in principle, in MASS on this I didn't already  \nknow.  My question is just more about the functioning of the lm  \ncommand and deriving these values.  I understand that its the wrong  \napproach for repeated measures design and lme is more appropriate.   \nBut, I wanted to examine / compare.  So, my question still stands.   \nHow does one get something like the subject x effect interaction term  \nfrom lm?\n\nAlso, while I'm at it, anyone familiar with Blouin & Riopelle on  \nconfidence intervals and repeated measures deigns?  Is there a reason  \nthe intervals() command should give me different values for the  \nnarrow inference confidence intervals than they get from SAS?\n\nOn May 17, 2007, at 2:20 PM, Bert Gunter wrote:\n\n> You need to gain some background. MIXED EFFECTS MODELS in S and S- \n> PLUS by\n> Pinheiro and Bates is a canonical reference for how to do this with R.\n> Chapter 10  of Venables and Ripley's MASS(4th ed.) contains a more  \n> compact\n> but very informative overview that may suffice. Other useful  \n> references can\n> also be found on CRAN.\n>\n>\n> Bert Gunter\n> Genentech Nonclinical Statistics\n>\n> -----Original Message-----\n> From: r-help-bounces@stat.math.ethz.ch\n> [mailto:r-help-bounces@stat.math.ethz.ch] On Behalf Of John Christie\n> Sent: Thursday, May 17, 2007 10:06 AM\n> To: R-help@stat.math.ethz.ch\n> Subject: [R] repeated measures regression\n>\n>\n> How does one go about doing a repeated measure regression? The\n> documentation I have on it (Lorch & Myers 1990) says to use linear /\n> (subj x linear) to get your F.  However, if I put subject into glm or\n> lm I can't get back a straight error term because it assumes\n> (rightly) that subject is a nominal predictor of some sort.\n>\n> In looking at LME it seems like it just does the right thing here if\n> I enter the random effect the same as when looking for ANOVA like\n> results out of it.  But, part of the reason I'm asking is that I\n> wanted to compare the two methods.  I suppose I could get it out of\n> aov but isn't that built on lm?  I guess what I'm asking is how to\n> calculate the error terms easily with lm.\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}