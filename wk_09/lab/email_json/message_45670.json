{"category": "ham", "to_address": "\"Martin Henry H. Stevens\" <HStevens@muohio.edu>", "from_address": "\"Robert Wilkins\" <irishhacker@gmail.com>", "subject": "Re: [R] Tools For Preparing Data For Analysis", "body": "Here are some examples of the type of data crunching you might have to do.\n\nIn response to the requests by Christophe Pallier and Martin Stevens.\n\nBefore I started developing Vilno, some six years ago, I had been working in\nthe pharmaceuticals for eight years ( it's not easy to show you actual data\nthough, because it's all confidential of course).\n\nLab data can be especially messy, especially if one clinical trial allows\nthe physicians to use different labs. So let's consider lab data.\n\nMerge in normal ranges, into the lab data. This has to be done by lab-site\nand lab testcode(PLT for platelets, etc.), obviously. I've seen cases where\nyou also need to match by sex and age. The sex column in the normal ranges\ncould be: blank, F, M, or B ( B meaning for Both sexes). The age column in\nthe normal ranges could be: blank, or something like \"40 <55\". Even worse,\nyou could have an ageunits column in the normal ranges dataset: usually \"Y\",\nbut if there are children in the clinical trial, you will have \"D\" or \"M\",\nfor Days and Months. If the clinical trial is for adults, all rows with \"D\"\nor \"M\" should be tossed out at the start. Clearly the statistical programmer\nhas to spend time looking at the data, before writing the program. Remember,\nall of these details can change any time you move to a new clinical trial.\n\nSo for the lab data, you have to merge in the patient's date of birth,\ncalculate age, and somehow relate that to the age-group column in the normal\nranges dataset.\n\n(By the way, in clinical trial data preparation, the SAS datastep is much\nmore useful and convenient, in my opinion, than the SQL SELECT syntax, at\nleast 97% of the time. But in the middle of this program, when you merge the\nnormal ranges into the lab data, you get a better solution with PROC SQL (\njust the SQL SELECT statement implemented inside SAS) This is because of the\ntrickiness of the age match-up, and the SAS datastep does not do well with\nmany-to-many joins.).\n\nMerge in various study drug administration dates into the lab data. Now, for\neach lab record, calculate treatment period ( or cycle number ), depending\non the statistician's specifications and the way the clinical trial is\nstructured.\n\nDifferent clinical sites chose to use different lab providers. So, for\nexample, for Monocytes, you have 10 different units ( essentially 6 units,\nbut spelling inconsistencies as well). The statistician has requested that\nyou use standardized units in some of the listings ( % units, and only one\ntype of non-% unit, for example ). At the same time, lab values need to be\nconverted ( *1.61 , divide by 1000, etc. ). This can be very time consuming\nno matter what software you use, and, in my experience, when the SAS\nprogrammer asks for more clinical information or lab guidebooks, the\nresponse is incomplete, so he does a lot of guesswork. SAS programmers do\nnot have expertise in lab science, hence the guesswork.\n\nYour program has to accomodate numeric values, \"1.54\" , quasi-numeric values\n\"<1\" , and non-numeric values \"Trace\".\n\nYour data listing is tight for space, so print \"PROLONGED CELL CONT\" as\n\"PRCC\".\n\nOnce normal ranges are merged in, figure out which values are out-of-range\nand high , which are low, and which are within normal range. In the data\nlisting, you may have \"H\" or \"L\" appended to the result value being printed.\n\nFor each treatment period, you may need a unique lab record selected, in\ncase there are two or three for the same treatment period. The statistician\nwill tell the SAS programmer how. Maybe the averages of the results for that\ntreatment period, maybe that lab record closest to the mid-point of of the\ntreatment period. This isn't for the data listing, but for a summary table.\n\nFor the differentials ( monocytes, lymphocytes, etc) , merge in the WBC\n(total white blood cell count) values , to convert values between % units\nand absolute count units.\n\nWhen printing the values in the data listing, you need \"H\" or \"L\" to the\nright of the value. But you also need the values to be well lined up ( the\ndecimal place ). This can be stupidly time consuming.\n\n\n\nAND ON AND ON AND ON .....\n\nI think you see why clinical trials statisticians and SAS programmers enjoy\nlots of job security.\n\n\n\nOn 6/8/07, Martin Henry H. Stevens  wrote:\n>\n> Is there an example available of this sort of problematic data that\n> requires this kind of data screening and filtering? For many of us,\n> this issue would be nice to learn about, and deal with within R. If a\n> package could be created, that would be optimal for some of us. I\n> would like to learn a tad more, if it were not too much effort for\n> someone else to point me in the right direction?\n> Cheers,\n> Hank\n> On Jun 8, 2007, at 8:47 AM, Spielas Bates wrote:\n>\n> > On 6/7/07, Robert Wilkins  wrote:\n> >> As noted on the R-project web site itself ( www.r-project.org ->\n> >> Manuals -> R Data Import/Export ), it can be cumbersome to prepare\n> >> messy and dirty data for analysis with the R tool itself. I've also\n> >> seen at least one S programming book (one of the yellow Springer\n> >> ones)\n> >> that says, more briefly, the same thing.\n> >> The R Data Import/Export page recommends examples using SAS, Perl,\n> >> Python, and Java. It takes a bit of courage to say that ( when you go\n> >> to a corporate software web site, you'll never see a page saying\n> >> \"This\n> >> is the type of problem that our product is not the best at, here's\n> >> what we suggest instead\" ). I'd like to provide a few more\n> >> suggestions, especially for volunteers who are willing to evaluate\n> >> new\n> >> candidates.\n> >>\n> >> SAS is fine if you're not paying for the license out of your own\n> >> pocket. But maybe one reason you're using R is you don't have\n> >> thousands of spare dollars.\n> >> Using Java for data cleaning is an exercise in sado-masochism, Java\n> >> has a learning curve (almost) as difficult as C++.\n> >>\n> >> There are different types of data transformation, and for some data\n> >> preparation problems an all-purpose programming language is a good\n> >> choice ( i.e. Perl , or maybe Python/Ruby ). Perl, for example, has\n> >> excellent regular expression facilities.\n> >>\n> >> However, for some types of complex demanding data preparation\n> >> problems, an all-purpose programming language is a poor choice. For\n> >> example: cleaning up and preparing clinical lab data and adverse\n> >> event\n> >> data - you could do it in Perl, but it would take way, way too much\n> >> time. A specialized programming language is needed. And since data\n> >> transformation is quite different from data query, SQL is not the\n> >> ideal solution either.\n> >>\n> >> There are only three statistical programming languages that are\n> >> well-known, all dating from the 1970s: SPSS, SAS, and S. SAS is more\n> >> popular than S for data cleaning.\n> >>\n> >> If you're an R user with difficult data preparation problems, frankly\n> >> you are out of luck, because the products I'm about to mention are\n> >> new, unknown, and therefore regarded as immature. And while the\n> >> founders of these products would be very happy if you kicked the\n> >> tires, most people don't like to look at brand new products. Most\n> >> innovators and inventers don't realize this, I've learned it the hard\n> >> way.\n> >>\n> >> But if you are a volunteer who likes to help out by evaluating,\n> >> comparing, and reporting upon new candidates, well you could\n> >> certainly\n> >> help out R users and the developers of the products by kicking the\n> >> tires of these products. And there is a huge need for such\n> >> volunteers.\n> >>\n> >> 1. DAP\n> >> This is an open source implementation of SAS.\n> >> The founder: Susan Bassein\n> >> Find it at: directory.fsf.org/math/stats (GNU GPL)\n> >>\n> >> 2. PSPP\n> >> This is an open source implementation of SPSS.\n> >> The relatively early version number might not give a good idea of how\n> >> mature the\n> >> data transformation features are, it reflects the fact that he has\n> >> only started doing the statistical tests.\n> >> The founder: Ben Pfaff, either a grad student or professor at\n> >> Stanford CS dept.\n> >> Also at : directory.fsf.org/math/stats (GNU GPL)\n> >>\n> >> 3. Vilno\n> >> This uses a programming language similar to SPSS and SAS, but\n> >> quite unlike S.\n> >> Essentially, it's a substitute for the SAS datastep, and also\n> >> transposes data and calculates averages and such. (No t-tests or\n> >> regressions in this version). I created this, during the years\n> >> 2001-2006 mainly. It's version 0.85, and has a fairly low bug\n> >> rate, in\n> >> my opinion. The tarball includes about 100 or so test cases used for\n> >> debugging - for logical calculation errors, but not for extremely\n> >> high\n> >> volumes of data.\n> >> The maintenance of Vilno has slowed down, because I am currently\n> >> (desparately) looking for employment. But once I've found new\n> >> employment and living quarters and settled in, I will continue to\n> >> enhance Vilno in my spare time.\n> >> The founder: that would be me, Robert Wilkins\n> >> Find it at: code.google.com/p/vilno ( GNU GPL )\n> >> ( In particular, the tarball at code.google.com/p/vilno/downloads/\n> >> list\n> >> , since I have yet to figure out how to use Subversion ).\n> >>\n> >> 4. Who knows?\n> >> It was not easy to find out about the existence of DAP and PSPP. So\n> >> who knows what else is out there. However, I think you'll find a lot\n> >> more statistics software ( regression , etc ) out there, and not so\n> >> much data transformation software. Not many people work on data\n> >> preparation software. In fact, the category is so obscure that there\n> >> isn't one agreed term: data cleaning , data munging , data\n> >> crunching ,\n> >> or just getting the data ready for analysis.\n> >\n> > Thanks for bringing up this topic.  I think there is definitely a\n> > place for such languages, which I would regard as data-filtering\n> > languages, but I also think that trying to reproduce the facilities in\n> > SAS or SPSS for data analysis is redundant.\n> >\n> > Other responses in this thread have mentioned 'little language'\n> > filters like awk, which is fine for those who were raised in the Bell\n> > Labs tradition of programming (\"why type three characters when two\n> > character names should suffice for anything one wants to do on a\n> > PDP-11\") but the typical field scientist finds this a bit too terse to\n> > understand and would rather write a filter as a paragraph of code that\n> > they have a change of reading and understanding a week later.\n> >\n> > Frank Harrell indicated that it is possible to do a lot of difficult\n> > data transformation within R itself if you try hard enough but that\n> > sometimes means working against the S language and its \"whole object\"\n> > view to accomplish what you want and it can require knowledge of\n> > subtle aspects of the S language.\n> >\n> > General scripting languages like Perl, Python and Ruby can certainly\n> > be used for data filtering but that means learning the language and\n> > its idiosyncrasies, and those idiosyncrasies are often exactly the\n> > aspects that would be used to write a filter tersely.  Readability\n> > suffers.  (\"Hell is reading someone else's Perl code - purgatory is\n> > reading your own Perl code.\")  The very generality of the languages\n> > means there is a lot to learn and understand before you can write\n> > something like a simple filter.\n> >\n> > So I do agree that it would be useful to have a language like the SAS\n> > data step (but Open Source, of course) in which to write a data\n> > filter.  I have one suggestion to make - use the R data frame\n> > structure in the form of a .rda file as the binary output format for a\n> > data table.  That way the user can get the best of both worlds by\n> > using a language like Viino to manipulate and rearrange huge data\n> > files then switching to R for the graphics and data analysis.  As a\n> > further enhancement one might provide the ability to take a .rda file\n> > that contains a single data frame and select columns or rows,\n> > including a random sample of the rows, as a filter.\n> >\n> > Producing an R data frame may involve passing over the data twice,\n> > once to determine the size of the resulting structure and the second\n> > time to evaluate the data itself.  This would have been a horrific\n> > penalty in the days that SAS and SPSS were developed but not now.\n> >\n> > ______________________________________________\n> > R-help@stat.math.ethz.ch mailing list\n> > https://stat.ethz.ch/mailman/listinfo/r-help\n> > PLEASE do read the posting guide http://www.R-project.org/posting-\n> > guide.html\n> > and provide commented, minimal, self-contained, reproducible code.\n>\n>\n>\n> Dr. Hank Stevens, Assistant Professor\n> 338 Pearson Hall\n> Botany Department\n> Miami University\n> Oxford, OH 45056\n>\n> Office: (513) 529-4206\n> Lab: (513) 529-4262\n> FAX: (513) 529-4243\n> http://www.cas.muohio.edu/~stevenmh/\n> http://www.muohio.edu/ecology/\n> http://www.muohio.edu/botany/\n>\n> \"E Pluribus Unum\"\n>\n>\n>\n>\n>\n>\n\n\t[[alternative HTML version deleted]]\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}