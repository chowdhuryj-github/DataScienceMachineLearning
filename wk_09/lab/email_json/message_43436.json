{"category": "ham", "to_address": "\"Kuhn, Max\" <Max.Kuhn@pfizer.com>", "from_address": "Uwe Ligges <ligges@statistik.uni-dortmund.de>", "subject": "Re: [R] naiveBayes other than e1071", "body": "Dear Max,\n\nthanks for your work on this!\nI totally agree in all points and have added some check for zero \nvariances to my working copy of NaiveBayes.default() which will be \npublished in the next klaR release.\n\n   if(!usekernel){\n     temp <- apply(sapply(tables, function(x) x[,2]), 2,\n                   function(x) any(!x))\n     if(any(temp))\n       stop(\"Zero variances for at least one class in variables: \",\n            paste(names(tables)[temp], collapse=\", \"))\n   }\n\n\nThanks again,\nUwe\n\n\n\n\nKuhn, Max wrote:\n> Saeed and Uwe,\n> \n> The underlying problem is the distribution of the data. For example:\n> \n>> table(x.x[,91], y.y)\n>              y.y\n>                  0    1\n>   0.000675027 2412    0\n>   0.002184892    0  481\n> \n> When the function tries to estimate the distribution of this feature for\n> each class, it gets:\n> \n>    nb$tables[[91]]\n>             [,1] [,2]\n>    0 0.000675027    0\n>    1 0.002184892    0\n> \n> (Saeed - column 1 contains the means for each class and column 2\n> contains the variances)\n>  \n> For class 0, if a new data point for this variable has a value of\n> 0.000675027, then dnorm(0.000675027, 0.000675027, 0) = Inf (all other\n> points have density values of zero). When the data are normalized by\n> p(x), this produces a NaN. A few of the predictors have this problem.\n> \n> There should probably be some sort of check for this, but that might be\n> hard to do when usekernel = TRUE. Uwe - do you agree and/or have ideas? \n> \n> Good news Saeed! Just use variable 91 and you don't need a model.\n> Seriously, you might want to think about these data a bit. Many of them\n> are highly skewed and have a large point mass at zero. Modeling the\n> conditional probabilities using a normal distribution may not be the\n> best idea.\n> \n> Max\n> \n> \n> -----Original Message-----\n> From: Uwe Ligges [mailto:ligges@statistik.uni-dortmund.de] \n> Sent: Tuesday, June 05, 2007 3:56 PM\n> To: Saeed Abu Nimeh\n> Cc: Kuhn, Max; r-help@stat.math.ethz.ch\n> Subject: Re: [R] naiveBayes other than e1071\n> \n> \n> \n> Saeed Abu Nimeh wrote:\n>> Max,\n>> Thanks. I have tried it but i keep getting an error:\n>> Error in as.vector(x, mode) : invalid argument 'mode'\n>> Do I have to do something specific when using the class column. I\n> tried\n>> both  y.y<-as.vector and y.y<-as.factor.\n>>\n>> dread<-read.table('dataset.csv',sep=\",\")\n>> x.x<-as.matrix(dread[,2:256])\n>> y.y<-as.vector(dread[,1])\n>> nb<- NaiveBayes(x=x.x,grouping=y.y)\n>> pred.nb<-predict(nb)\n>>\n>> Error in as.vector(x, mode) : invalid argument 'mode'\n> \n> \n> \n> Please tell us (according to the posting guide): Which version of R? \n> Which version of klaR? Example data that reproduce the error?\n> \n> Uwe Ligges\n> \n> \n> \n>> Thanks,\n>> Saeed\n>>\n>> Kuhn, Max wrote:\n>>> Saeed,\n>>>\n>>> There is a version in the klaR package. I recently submitted a change\n> to\n>>> the predict function that may be related to your problem. \n>>>\n>>> If:\n>>>\n>>>   1. the posterior probabilities (apart from the prior) are being\n>>> approximated by the product of the p(x_i|y_j) and\n>>>\n>>>   2. a lot of predictors are being used\n>>>\n>>> then posterior probabilities may have values of absolute zero. \n>>>\n>>> When the approximation is used, the approximate posterior\n> probabilities\n>>> are normalized by their sum (which is zero in such cases).\n>>>\n>>> The patch in klaR uses the product of the conditional divided by the\n>>> marginal of x_i (per the true formula). I haven't seen the problem\n> occur\n>>> with this patch.\n>>>\n>>> HTH,\n>>>\n>>> Max\n>>>\n>>> -----Original Message-----\n>>> From: r-help-bounces@stat.math.ethz.ch\n>>> [mailto:r-help-bounces@stat.math.ethz.ch] On Behalf Of Saeed Abu\n> Nimeh\n>>> Sent: Monday, June 04, 2007 2:45 PM\n>>> To: r-help@stat.math.ethz.ch\n>>> Subject: [R] naiveBayes other than e1071\n>>>\n>>> Hi List,\n>>> Is there a naiveBayes interface other than the one in e1071 package.\n> For\n>>> some reason on certain datasets all predicted values are NaN, but it\n>>> predicts well on others.\n>>> Thanks,\n>>> Saeed\n>>> ---\n>>> model <- naiveBayes(x.train, y.train, laplace = 3)\n>>> pred <- predict(model,x.test,type=\"raw\")\n>>>\n>>> ______________________________________________\n>>> R-help@stat.math.ethz.ch mailing list\n>>> https://stat.ethz.ch/mailman/listinfo/r-help\n>>> PLEASE do read the posting guide\n>>> http://www.R-project.org/posting-guide.html\n>>> and provide commented, minimal, self-contained, reproducible code.\n>>>\n>>>\n> ----------------------------------------------------------------------\n>>> LEGAL NOTICE\n>>> Unless expressly stated otherwise, this message is confidential and\n> may be privileged.  It is intended for the addressee(s) only.  Access to\n> this E-mail by anyone else is unauthorized.  If you are not an\n> addressee, any disclosure or copying of the contents of this E-mail or\n> any action taken (or not taken) in reliance on it is unauthorized and\n> may be unlawful.  If you are not an addressee, please inform the sender\n> immediately.\n>> ______________________________________________\n>> R-help@stat.math.ethz.ch mailing list\n>> https://stat.ethz.ch/mailman/listinfo/r-help\n>> PLEASE do read the posting guide\n> http://www.R-project.org/posting-guide.html\n>> and provide commented, minimal, self-contained, reproducible code.\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}