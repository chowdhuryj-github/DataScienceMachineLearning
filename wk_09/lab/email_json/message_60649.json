{"category": "ham", "to_address": "r-help@stat.math.ethz.ch", "from_address": "Mark Difford <mark_difford@yahoo.co.uk>", "subject": "Re: [R] Question about PCA with prcomp", "body": "\nTo all ...,\n\nBill's \"lateral\" wisdom is almost certainly a better solution.  So thanks\nfor the advice (and everything else that went before it [Bill: apropos of\ntermplot, what happened to tplot ?]).  And I will [almost] desist from\nasking the obvious: and if there were 10 000 observations ?\n\nBestR,\nMark.\n\n\nBill.Venables wrote:\n> \n> ...but with 500 variables and only 20 'entities' (observations) you will\n> have 481 PCs with dead zero eigenvalues.  How small is 'smaller' and how\n> many is \"a few\"?\n> \n> Everyone who has responded to this seems to accept the idea that PCA is\n> the way to go here, but that is not clear to me at all.  There is a\n> 2-sample structure in the 20 observations that you have.  If you simply\n> ignore that in doing your PCA you are making strong assumptions about\n> sampling that would seem to me unlikely to be met.  If you allow for the\n> structure and project orthogonal to it then you are probably throwing\n> the baby out with the bathwater - you want to choose variables which\n> maximise separation between the 2 samples (and now you are up to 482\n> zero principal variances, if that matters...).\n> \n> I think this problem probably needs a bit of a re-think.  Some variant\n> on singular LDA, for example, may be a more useful way to think about\n> it.\n> \n> Bill Venables.  \n> \n> -----Original Message-----\n> From: r-help-bounces@stat.math.ethz.ch\n> [mailto:r-help-bounces@stat.math.ethz.ch] On Behalf Of Ravi Varadhan\n> Sent: Monday, 2 July 2007 1:29 PM\n> To: 'Patrick Connolly'\n> Cc: r-help@stat.math.ethz.ch; 'Mark Difford'\n> Subject: Re: [R] Question about PCA with prcomp\n> \n> The PCs that are associated with the smaller eigenvalues. \n> \n> ------------------------------------------------------------------------\n> ----\n> -------\n> \n> Ravi Varadhan, Ph.D.\n> \n> Assistant Professor, The Center on Aging and Health\n> \n> Division of Geriatric Medicine and Gerontology \n> \n> Johns Hopkins University\n> \n> Ph: (410) 502-2619\n> \n> Fax: (410) 614-9625\n> \n> Email: rvaradhan@jhmi.edu\n> \n> Webpage:\n> http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html\n> \n>  \n> \n> ------------------------------------------------------------------------\n> ----\n> --------\n> \n> -----Original Message-----\n> From: Patrick Connolly [mailto:p_connolly@ihug.co.nz]\n> Sent: Monday, July 02, 2007 4:23 PM\n> To: Ravi Varadhan\n> Cc: 'Mark Difford'; r-help@stat.math.ethz.ch\n> Subject: Re: [R] Question about PCA with prcomp\n> \n> On Mon, 02-Jul-2007 at 03:16PM -0400, Ravi Varadhan wrote:\n> \n> |> Mark,\n> |> \n> |> What you are referring to deals with the selection of covariates, \n> |> since\n> PC\n> |> doesn't do dimensionality reduction in the sense of covariate\n> selection.\n> |> But what Mark is asking for is to identify how much each data point \n> |> contributes to individual PCs.  I don't think that Mark's query makes\n> much\n> |> sense, unless he meant to ask: which individuals have high/low scores\n> \n> |> on PC1/PC2.  Here are some comments that may be tangentially related \n> |> to\n> Mark's\n> |> question:\n> |> \n> |> 1.  If one is worried about a few data points contributing heavily to\n> \n> |> the estimation of PCs, then one can use robust PCA, for example, \n> |> using robust covariance matrices.  MASS has some tools for this.\n> |> 2.  The \"biplot\" for the first 2 PCs can give some insights 3. PCs, \n> |> especially, the last few PCs, can be used to identify \"outliers\".\n> \n> What is meant by \"last few PCs\"?\n> \n> -- \n> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.\n> \n>    ___    Patrick Connolly   \n>  {~._.~}          \t\t Great minds discuss ideas    \n>  _( Y )_  \t  \t        Middle minds discuss events \n> (:_~*~_:) \t       \t\t Small minds discuss people  \n>  (_)-(_)  \t                           ..... Anon\n> \t  \n> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.\n> \n> ______________________________________________\n> R-help@stat.math.ethz.ch mailing list\n> https://stat.ethz.ch/mailman/listinfo/r-help\n> PLEASE do read the posting guide\n> http://www.R-project.org/posting-guide.html\n> and provide commented, minimal, self-contained, reproducible code.\n> \n> ______________________________________________\n> R-help@stat.math.ethz.ch mailing list\n> https://stat.ethz.ch/mailman/listinfo/r-help\n> PLEASE do read the posting guide\n> http://www.R-project.org/posting-guide.html\n> and provide commented, minimal, self-contained, reproducible code.\n> \n> \n\n-- \nView this message in context: http://www.nabble.com/Question-about-PCA-with-prcomp-tf4012919.html#a11402204\nSent from the R help mailing list archive at Nabble.com.\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}