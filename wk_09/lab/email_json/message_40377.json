{"category": "ham", "to_address": "\"'jiho'\" <jo.irisson@gmail.com>", "from_address": "\"Tom La Bone\" <labone@gforcecable.com>", "subject": "Re: [R] Problem with Weighted Variance in Hmisc", "body": "Wonderful!  Thanks for the assistance.\n\nTom La Bone\n\n\n-----Original Message-----\nFrom: jiho [mailto:jo.irisson@gmail.com] \nSent: Friday, June 01, 2007 8:17 AM\nTo: labone@gforcecable.com\nCc: 'R-help'\nSubject: Re: [R] Problem with Weighted Variance in Hmisc\n\nOn 2007-June-01  , at 13:00 , Tom La Bone wrote:\n> The equation for weighted variance given in the NIST DataPlot  \n> documentation\n> is the usual variance equation with the weights inserted.  The  \n> weighted\n> variance of the weighted mean is this weighted variance divided by N.\n>\n> There is another approach to calculating the weighted variance of the\n> weighted mean that propagates the uncertainty of each term in the  \n> weighted\n> mean (see Data Reduction and Error Analysis for the Physical  \n> Sciences by\n> Bevington & Robinson).  The two approaches do not give the same  \n> answer. Can\n> anyone suggest a reference that discusses the merits of the DataPlot\n> approach versus the Bevington approach?\n\nI am no expert but I did a little research on the subject and it  \nseems there is no analytical equivalent to the standard error of the  \nmean in weighted statistics (i.e. there is no standard error/variance  \nof the weighted mean). That's why you find so many formulas: they are  \nall numerical approximations that make more of less sense. If you  \nhave access to DcienceDirect there is a paper which compares 3 of  \nthose analytical approximations to the variance estimated by bootstrap:\n\n@article{Gatz1995AE,\n\tAuthor = {Gatz, Donald F and Smith, Luther},\n\tDate-Added = {2007-05-19 14:15:58 +0200},\n\tDate-Modified = {2007-06-01 14:12:17 +0200},\n\tFiled = {Yes},\n\tJournal = {Atmospheric Environment},\n\tNumber = {11},\n\tPages = {1185--1193},\n\tRating = {0},\n\tTitle = {The standard error of a weighted mean concentration--I.  \nBootstrapping vs other methods},\n\tUrl =\n{http://www.sciencedirect.com/science/article/B6VH3-3YGV47C-6X/ \n2/18b627259a75ff9b765410aaa231e352},\n\tVolume = {29},\n\tYear = {1995},\n\tAbstract = {Concentrations of chemical constituents of precipitation\n\nare frequently expressed in terms of the precipitation-weighted mean,  \nwhich has several desirable properties. Unfortunately, the weighted  \nmean has no analytical analog of the standard error of the arithmetic  \nmean for use in characterizing its statistical uncertainty. Several  \napproximate expressions have been used previously in the literature,  \nbut there is no consensus as to which is best. This paper compares  \nthree methods from the literature with a standard based on  \nbootstrapping. Comparative calculations were carried out for nine  \nmajor ions measured at 222 sampling sites in the National Atmospheric  \nDeposition/National Trends Network (NADP/NTN). The ratio variance  \napproximation of Cochran (1977) gave results that were not  \nstatistically different from those of bootstrapping, and is suggested  \nas the method of choice for routine computing of the standard error  \nof the weighted mean. The bootstrap method has advantages of its own,  \nincluding the fact that it is nonparametric, but requires additional  \neffort and computation time.}}\n\nThe analytical formula which is the closest to the bootstrap  is this  \none:\n\nvar.wtd.mean.cochran <- function(x,w)\n#\n#\tComputes the variance of a weighted mean following Cochran 1977  \ndefinition\n#\n{\n\tn = length(w)\n\txWbar = wtd.mean(x,w)\n\twbar = mean(w)\n\tout = n/((n-1)*sum(w)^2)*(sum((w*x-wbar*xWbar)^2)-2*xWbar*sum((w- \nwbar)*(w*x-wbar*xWbar))+xWbar^2*sum((w-wbar)^2))\n\treturn(out)\n}\n\nIt's the one I am retaining.\n\nNB: the part two of the paper cited above may also interest you:\n\n@article{Gatz1995AEa,\n\tAuthor = {Gatz, Donald F and Smith, Luther},\n\tDate-Added = {2007-05-19 14:15:58 +0200},\n\tDate-Modified = {2007-06-01 12:11:53 +0200},\n\tFiled = {Yes},\n\tJournal = {Atmospheric Environment},\n\tNumber = {11},\n\tPages = {1195--1200},\n\tTitle = {The standard error of a weighted mean concentration--II.  \nEstimating confidence intervals},\n\tUrl =\n{http://www.sciencedirect.com/science/article/B6VH3-3YGV47C-6Y/ \n2/a187487377ef52b741e3dabdfca97517},\n\tVolume = {29},\n\tYear = {1995},\n\tAbstract = {One motivation for estimating the standard error, SEMw,\n\nof a weighted mean concentration, Mw, of an ion in precipitation is  \nto use it to compute a confidence interval for Mw. Typically this is  \ndone by multiplying the standard error by a factor that depends on  \nthe degree of confidence one wishes to express, on the assumption  \nthat the weighted mean has a normal distribution. This paper compares  \nconfidence intervals of Mw concentrations of ions in precipitation,  \nas computed using the assumption of a normal distribution, with those  \nestimated from distributions produced by bootstrapping. The  \nhypothesis that Mw was normally distributed was rejected about half  \nthe time (at the 5{\\%} significance level) in tests involving nine  \nmajor ions measured at ten diverse sites in the National Atmospheric  \nDeposition Program/National Trends Network (NADP/NTN). Most of these  \nrejections occurred at sites with fewer than 100 samples, in  \nagreement with previous results. Nevertheless, the hypothesis was  \noften rejected at sites with more than 100 samples as well. The  \nmaximum error (relative to Mw) in the 95{\\%} confidence limits made  \nby assuming a normal distribution of the Mw at the ten sites examined  \nwas about 27{\\%}. Most such errors were less than 10{\\%}, and errors  \nwere smaller at sampling sites with > 100 samples than at those with  \n< 100 samples.}}\n\nCheers,\n\nJiHO\n---\nhttp://jo.irisson.free.fr/\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}