{"category": "ham", "to_address": "hadley wickham <h.wickham@gmail.com>", "from_address": "Adaikalavan Ramasamy <ramasamy@cancer.org.uk>", "subject": "Re: [R] Weighted least squares", "body": "See below.\n\nhadley wickham wrote:\n> Dear all,\n> \n> I'm struggling with weighted least squares, where something that I had\n> assumed to be true appears not to be the case.  Take the following\n> data set as an example:\n> \n> df <- data.frame(x = runif(100, 0, 100))\n> df$y <- df$x + 1 + rnorm(100, sd=15)\n> \n> I had expected that:\n> \n> summary(lm(y ~ x, data=df, weights=rep(2, 100)))\n> summary(lm(y ~ x, data=rbind(df,df)))\n\nYou assign weights to different points according to some external \nquality or reliability measure not number of times the data point was \nmeasured.\n\nLook at the estimates and standard error of the two models below:\n\n  coefficients( summary(f.w <- lm(y ~ x, data=df, weights=rep(2, 100))) )\n              Estimate Std. Error   t value     Pr(>|t|)\n  (Intercept) 1.940765 3.30348066  0.587491 5.582252e-01\n  x           0.982610 0.05893262 16.673448 2.264258e-30\n\n  coefficients( summary( f.u <- lm(y ~ x, data=rbind(df,df) ) ) )\n              Estimate Std. Error    t value     Pr(>|t|)\n  (Intercept) 1.940765 2.32408609  0.8350659 4.046871e-01\n  x           0.982610 0.04146066 23.6998165 1.012067e-59\n\nYou can see that they have same coefficient estimates but the second one \n  has smaller variances.\n\nThe repeated values artificially deflates the variance and thus inflates \nthe precision. This is why you cannot treat replicate data as \nindependent observations.\n\n\n> would be equivalent, but they are not.  I suspect the difference is\n> how the degrees of freedom is calculated - I had expected it to be\n> sum(weights), but seems to be sum(weights > 0).  This seems\n> unintuitive to me:\n> \n> summary(lm(y ~ x, data=df, weights=rep(c(0,2), each=50)))\n> summary(lm(y ~ x, data=df, weights=rep(c(0.01,2), each=50)))\n> \n> What am I missing?  And what is the usual way to do a linear\n> regression when you have aggregated data?\n\nI would be best to use the individual data points instead of aggregated \ndata as it allows you to estimate the within-group variations as well.\n\nIf you had individual data points, you could try something as follows. \nPlease check the codes as I am no expert in the area of repeated measures.\n\n  x  <- runif(100, 0, 100)\n  y1 <- x + rnorm(100, mean=1, sd=15)\n  y2 <- y1 + rnorm(100, sd=5)\n\n  df <- data.frame( y=c(y1, y2),\n                    x=c(x,x),\n                    subject=factor(rep( paste(\"p\", 1:100, sep=\"\"), 2 ) ))\n\n  library(nlme)\n  summary( lme( y ~ x, random = ~ 1 | subject, data=df ) )\n\nTry reading Pinheiro and Bates (http://tinyurl.com/yvvrr7) or related \nmaterial for more information. Hope this helps.\n\n> Thanks,\n> \n> Hadley\n\nRegards, Adai\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}