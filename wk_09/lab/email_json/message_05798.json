{"category": "ham", "to_address": "Sean Scanlan <sscanlan@stanford.edu>", "from_address": "Peter Dalgaard <p.dalgaard@biostat.ku.dk>", "subject": "Re: [R] Hotelling T-Squared vs Two-Factor Anova", "body": "Sean Scanlan wrote:\n> Hi,\n>\n> I am a graduate student at Stanford University and I have a general\n> statistics question.  What exactly is the difference between doing a\n> two-factor repeated measures ANOVA and a Hotelling T-squared test for\n> a paired comparison of mean vectors?\n>\n> Given:\n>\n> Anova: repeated measures on both factors, 1st factor = two different\n> treatments, 2nd factor = 4 time points, where you are measuring the\n> blood pressure at each of the time points.\n>\n> Hotelling T^2: You look at the difference in the 4x1 vector of blood\n> pressure measurements for the two different treatments, where the four\n> rows in the vector are the four time points.\n>\n>\n> I am mainly interested in the main effects of the two treatments.  Can\n> someone please explain if there would be a difference in the two\n> methods or any advantage in using one over the other?\n>\n>   \nIn a few words (the full story takes a small book), the difference is in \nthe assumptions, and in the hypothesis being tested. In the most common \nincarnation, T^2 tests for *any* difference in the means, whereas ANOVA \nremoves the average before comparing the shapes of the time course. If \nyou look at intra-individual differences (e.g. x2-x1, x3-x2, x4-x3, but \nother choices are equivalent), then T^2 on these three variables will \ntest the same hypothesis about the means. The remaining difference is \nthen that ANOVA assumes a particular pattern of the covariance matrix, \nwhereas T^2 allows a general covariance structure. In particular, T^2 \napplies even when your response variables are not of the same quantity, \nsay if you had simultaneous measurements of heart rate and blood pressure.\n\nThe standard assumption for ANOVA is \"compound symmetry\" (one value on \nthe diagonal, another off-diagonal), which can be weakened to \n\"sphericity\" (covariance of differences behave as they would under \ncomp.symm.). On closer inspection, sphericity actually means that the \ncovariance matrix for differences is proportional to a known matrix.\n\nSince T^2 has more parameters to estimate it will have less power if \nboth methods are applicable. Even if the assumptions are not quite \nright, procedure based on the ANOVA F may still be stronger, but this \nrequires correction terms to be applied (these are known as \nGreenhouse-Geisser and Huynh-Feldt epsilons).\n> Thanks,\n> Sean\n>\n> ______________________________________________\n> R-help@stat.math.ethz.ch mailing list\n> https://stat.ethz.ch/mailman/listinfo/r-help\n> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html\n> and provide commented, minimal, self-contained, reproducible code.\n>\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}