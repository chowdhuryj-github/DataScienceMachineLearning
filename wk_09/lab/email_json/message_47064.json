{"category": "ham", "to_address": "\"Robert Wilkins\" <irishhacker@gmail.com>", "from_address": "\"Christophe Pallier\" <christophe@pallier.org>", "subject": "Re: [R] Awk and Vilno", "body": "On 6/13/07, Robert Wilkins  wrote:\n>\n> The point is : there are lots of data preparation scenarios where\n> large numbers of merges need to be done. This is an example where\n> Vilno and SAS are easier to use than the competition. I'm sure an Awk\n> programmer can come up with something, but the result would be\n> awkward.\n\n\nAgreed.\nIn the awk+R scenario, it is clear that the merges are often better done\nwith R.\nMy strategy is to use awk only to clean/reformat data into a tabular format\nand\ndo most of the \"consolidation\" (computations/filtering/merges) in R.  I\nsuggested to use awk only to perform manipulations that would be more\ncomplex to do within R (especially mutliline records or recors with\noptionnal fields). I try to keep the scripts as simple as possible on both\nsides\n\n\n\n> Certain apsects of Vilno and SAS are a bit more user-friendly:\n> > Each column has a variable name, such as \"PatientID\".\n> > Awk uses $1, $2, $3 , as variable names for columns. Not user-friendly.\n>\n>\n\n\nIn the first lines of awk scripts, I usually assign column numbers to\nvariables (e.g. \"Code=1, time=3\") and then access the fields with \"$Code\",\n\"$Time\"...\nYet, it is true that it is cumbersome, in awk, to use the labels on the\nfirst line of a file as a variable names (my major complain about awk).\n\nI looked at a few examples of  SAS Data step scripts on the Net, and found\nthat the awk scripts would be very similar (except for merges), but there\nmay  manipulations which I missed.\n\n\n> For scanning inconsistently structured ASCII data files, where\n> different rows have different column specifications, Awk is a better\n> tool.\n>\n> For data problems that lend themselves to UNIX-style regular\n> expressions, Awk, again, is a great tool.\n\n\n\nThe examples of messy data formats that were described ealier on the list\nare good examples where regular expressions will help a lot. In the very\nfirst stage of data inspection, to detect coding \"mistakes\", awk (sometimes\nwith the help ot other gnutools such as 'uniq' and 'sort') can be very\nefficient.\n\n> The upshot:\n\n> Awk is a hammer.\n> Vilno is a screwdriver.\n\nNice analogy. Using the right tool for the right task is very important.\nSo awk and vilno seem complementary.\nYet, when R enters into the equation, do you still \"need\" the three tools?\n\nWhat we should really compare is the four situations:\n\nR alone\nR + awk\nR + vilno\nR + awk + vilno\n\nand maybe \"R + SAS Data step\"\n\nand see what scripts are more  elegant (read 'short and understandable')\n\n\nBest,\n\nChristophe\n\n\n\n-- \nChristophe Pallier (http://www.pallier.org)\n\n\t[[alternative HTML version deleted]]\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}