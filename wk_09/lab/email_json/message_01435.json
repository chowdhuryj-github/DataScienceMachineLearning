{"category": "ham", "to_address": "ronggui <ronggui.huang@gmail.com>", "from_address": "Prof Brian Ripley <ripley@stats.ox.ac.uk>", "subject": "Re: [R] When to use quasipoisson instead of poisson family", "body": "On Tue, 10 Apr 2007, ronggui wrote:\n\n> On 4/10/07, Prof Brian Ripley  wrote:\n>> On Tue, 10 Apr 2007, Achim Zeileis wrote:\n>> \n>> > On Tue, 10 Apr 2007, ronggui wrote:\n>> >\n>> >> It seems that MASS suggest to judge on the basis of\n>> >> sum(residuals(mode,type=\"pearson\"))/df.residual(mode).\n>> \n>> Not really; that is the conventional moment estimator of overdispersion\n>> and it does not suffer from the severe biases the unreferenced estimate\n>> below has (and are illustrated in MASS).\n>> \n>> >> My question: Is\n>> >> there any rule of thumb of the cutpoiont value?\n>> >>\n>> >> The paper \"On the Use of Corrections for Overdispersion\"\n>> \n>> Whose paper?  It is churlish not to give credit, and unhelpful to your\n>> readers not to give a proper citation.\n>\n> Thanks for pointing this out. There is the citation:\n> @article{lindsey1999,\n> title={On the use of corrections for overdispersion},\n> author={Lindsey, JK},\n> journal={Applied Statistics},\n> volume={48},\n> number={4},\n> pages={553--561},\n> year={1999},\n> }\n\nAnd I can add 'it is helpful to know whose authority is being invoked', \nsince (e.g.) some authors are not at all careful.\n\n>> >> suggests overdispersion exists if the deviance is at least twice the\n>> >> number of degrees of freedom.\n>> \n>> Overdispersion _exists_:  'all models are wrong but some are useful'\n>> (G.E.P. Box).  The question is if it is important in your problem, not it\n>> if is detectable.\n>\n>\n>> > There are also formal tests for over-dispersion. I've implemented one \n>> for\n>> > a package which is not yet on CRAN (code/docs attached), another one is\n>> > implemented in odTest() in package \"pscl\". The latter also contains\n>> > further count data regression models which can deal with both\n>> > over-dispersion and excess zeros in count data. A vignette explaining \n>> the\n>> > tools is about to be released.\n>> \n>> There are, but like formal tests for outliers I would not advise using\n>> them, as you may get misleading inferences before they are significant,\n>> and they can reject when the inferences from the small model are perfectly\n>> adequate.\n>> \n>> In general, it is a much better idea to expand your models to take account\n>> of the sorts of departures your anticipate rather than post-hoc test for\n>> those departures and then if those tests do not fail hope that there is\n>> little effect on your inferences.\n>\n> Which is the better (or ) best way to expand the existing model?\n> by adding some other relevant independent variables or by using other\n> more suitable model like \"Negative Binomial Generalized Linear Model\"?\n\nI can think of several approaches to lack of fit of a Poisson GLM\n\n1) Missing explanatory variables.  If you have them, of course use them.\n\n2) Correlated observations, probably in groups.  Here a GEE model can be \nappropriate.\n\n3) Missing group random effects.  Similar in effect to 2) (and the random \neffects can even be correlated), but with a different interpretation.\n\n4) Missing random effects at individual level, hence count observations \nare from a Poisson mixture such as a negative binomial.\n\n5) Correlation at individual level, hence count observations are from a \nsum of correlated Poissons.\n\n6) Use moment inference, e.g. quasi models such as quasipoisson.  This \ndoes not care about the causal mechanism but adjusts for the some of the \neffects of some unknown mechanisms.  (GEE is similar.)\n\nYou may or may not be able to tell these apart depending on your design.\nHowever, it more often boils down to 'the sort of departures you \nanticipate' in choosing what to do.\n\n>\n> Thanks!\n>\n>> The moment estimator \\phi of over-dispersion gives you an indication of\n>> the likely effects on your inferences: e.g. estimated standard errors are\n>> proportional to \\sqrt(\\phi).  Having standard errors which need inflating\n>> by 40% seems to indicate that the rule you quote is too optimistic (even\n>> when its estimator is reliable).\n>> \n>> --\n>> Brian D. Ripley,                  ripley@stats.ox.ac.uk\n>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/\n>> University of Oxford,             Tel:  +44 1865 272861 (self)\n>> 1 South Parks Road,                     +44 1865 272866 (PA)\n>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595\n>> \n>\n>\n>\n\n-- \nBrian D. Ripley,                  ripley@stats.ox.ac.uk\nProfessor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/\nUniversity of Oxford,             Tel:  +44 1865 272861 (self)\n1 South Parks Road,                     +44 1865 272866 (PA)\nOxford OX1 3TG, UK                Fax:  +44 1865 272595\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}