{"category": "ham", "to_address": "r-help@stat.math.ethz.ch", "from_address": "Victor Gravenholt <victor.gravenholt@gmail.com>", "subject": "[R] sample() and memory usage", "body": "As a part of a simulation, I need to sample from a large vector repeatedly.\nFor some reason sample() builds up the memory usage (> 500 MB for this \nexample) when used inside a for loop as illustrated here:\n\nX <- 1:100000\nP <- runif(100000)\nfor(i in 1:500) Xsamp <- sample(X,30000,replace=TRUE,prob=P)\n\nEven worse, I am not able to free up memory without quitting R.\nI quickly run out of memory when trying to perform the simulation. Is \nthere any way to avoid this to happen?\n\nThe problem seem to appear only when specifying replace=TRUE and \nprobability weights for the vector being sampled, and this happens both \non Windows XP and Linux (Ubuntu).\n\n\nVictor\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}