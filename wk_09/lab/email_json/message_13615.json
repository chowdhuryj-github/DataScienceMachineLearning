{"category": "ham", "to_address": "Ravi Varadhan <rvaradhan@jhmi.edu>", "from_address": "DEEPANKAR BASU <basu.15@osu.edu>", "subject": "Re: [R] Estimates at each iteration of optim()?", "body": "Ravi,\n\nThanks a lot for your detailed reply. It clarifies many of the confusions in my mind. \n\nI want to look at the parameter estimates at each iteration because the full model that I am trying to estimate is not converging; a smaller version of the model converges but the results are quite meaningless. The problem in the estimation of the full model is the following: my likelihood function contains the elements of a (bivariate normal) covariance matrix as parameters. To compute the likelihood, I have to draw random samples from the bivariate normal distribution. But no matter what starting values I give, I cannot ensure that the covariance matrix remains positive definite at each iteration of the optimization exercise. Moreover, as soon as the covariance matrix fails to be positive definite, I get an error message (because I can no longer draw from the bivariate normal distribution) and the program stops. Faced with this problem, I wanted to see exactly at which parameter estimates the covariance matrix fails to remain positive definite. From that I would think of d\nevising a method to get around the problem, at least I would try to.  \n\nProbably there is some other way to solve this problem. I would like your opinion on the following question: is there some way I can transform the three parametrs of my (2 by 2) covariance matrix (the two standard devaitions and the correlation coefficient) to ensure that the covariance matrix remains positive definite at each iteration of the optimization. Is there any method other than transforming the parameters to ensure this?\n\nDeepankar\n\n\n\n----- Original Message -----\nFrom: Ravi Varadhan \nDate: Monday, April 23, 2007 12:21 pm\nSubject: RE: [R] Estimates at each iteration of optim()?\n\n> Deepankar,\n> \n> Here is an example using BFGS:\n> \n> > fr <- function(x) {   ## Rosenbrock Banana function\n> +     x1 <- x[1]\n> +     x2 <- x[2]\n> +     100 * (x2 - x1 * x1)^2 + (1 - x1)^2\n> + }\n> > grr <- function(x) { ## Gradient of 'fr'\n> +     x1 <- x[1]\n> +     x2 <- x[2]\n> +     c(-400 * x1 * (x2 - x1 * x1) - 2 * (1 - x1),\n> +        200 *      (x2 - x1 * x1))\n> + }\n> > optim(c(-1.2,1), fr, grr, method = \"BFGS\", control=list(trace=TRUE))\n> initial  value 24.200000 \n> iter  10 value 1.367383\n> iter  20 value 0.134560\n> iter  30 value 0.001978\n> iter  40 value 0.000000\n> final  value 0.000000 \n> converged\n> $par\n> [1] 1 1\n> \n> $value\n> [1] 9.594955e-18\n> \n> $counts\n> function gradient \n>     110       43 \n> \n> $convergence\n> [1] 0\n> \n> $message\n> NULL\n> \n> > \n> \n> This example shows that the parameter estimates are printed out \n> every 10\n> iterations.  However, trying different integer values for trace \n> from 2 to 10\n> (trace = 1 behaves the same as trace=TRUE) did not change anything. \n> If you\n> want to get estimates at every iteration, look at the source code \n> for BFGS\n> (which I assume is in FORTRAN). You may have to modify the source \n> code and\n> recompile it yourself to get more detailed trace for BFGS. \n> \n> However, you can get parameter iterates at every step for \"L-BFGS-\n> B\" using\n> trace=6, although this gives a lot more information than just the \n> parameterestimates.  Alternatively, you can use the \"CG\" methods \n> with trace=TRUE or\n> trace=1, which is a generally a lot slower than BFGS or L-BFGS-B.\n> \n> Why do you want to look at parameter estimates for each step, anyway?\n> \n> \n> Ravi.\n> \n> --------------------------------------------------------------------\n> --------\n> -------\n> \n> Ravi Varadhan, Ph.D.\n> \n> Assistant Professor, The Center on Aging and Health\n> \n> Division of Geriatric Medicine and Gerontology \n> \n> Johns Hopkins University\n> \n> Ph: (410) 502-2619\n> \n> Fax: (410) 614-9625\n> \n> Email: rvaradhan@jhmi.edu\n> \n> Webpage:  \n> http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html\n> \n> \n> --------------------------------------------------------------------\n> --------\n> --------\n> \n> -----Original Message-----\n> From: r-help-bounces@stat.math.ethz.ch\n> [r-help-bounces@stat.math.ethz.ch] On Behalf Of DEEPANKAR BASU\n> Sent: Monday, April 23, 2007 11:34 AM\n> To: Peter Dalgaard\n> Cc: r-help@stat.math.ethz.ch\n> Subject: Re: [R] Estimates at each iteration of optim()?\n> \n> I read the description of the trace control parameter in ?optim and \n> thenalso looked at the examples given at the end. In one of the \n> examples I found\n> that they had used \"trace=TRUE\"  with the method \"SANN\". I am using \n> themethod \"BFGS\" and I tried using \"trace=TRUE\" too but I did not \n> get the\n> parameter estimates at each iteration. As you say, it might be method\n> dependent. I tried reading the source code for \"optim\" but could \n> not find\n> out what I was looking for. Hence, I was wondering if anyone could \n> tell me\n> what option to use with the method \"BFGS\" to get the parameter \n> estimates at\n> each iteration of the optimization.\n> \n> Deepankar\n> \n> \n> ----- Original Message -----\n> From: Peter Dalgaard \n> Date: Monday, April 23, 2007 2:46 am\n> Subject: Re: [R] Estimates at each iteration of optim()?\n> \n> > DEEPANKAR BASU wrote:\n> > > I am trying to maximise a complicated loglikelihood function \n> with \n> > the \"optim\" command. Is there some way to get to know the \n> estiamtes \n> > at each iteration? When I put \"control=list(trace=TRUE)\" as an \n> > option in \"optim\", I just got the initial and final values of the \n> > loglikelihood, number of iterations and whether the routine has \n> > converged or not. I need to know the estimate values at each \n> > iteration.>\n> > >   \n> > It might help if you actually _read_ the description of the trace \n> > control parameter (hint: it is not an on/off switch) in ?optim... \n> > And, \n> > as it says, this is method dependent, so you may have to study \n> the \n> > source code.\n> > \n> > > Deepankar\n> > >\n> > > ______________________________________________\n> > > R-help@stat.math.ethz.ch mailing list\n> > > https://stat.ethz.ch/mailman/listinfo/r-help\n> > > PLEASE do read the posting guide http://www.R-\n> project.org/posting-\n> > guide.html> and provide commented, minimal, self-contained, \n> > reproducible code.\n> > >   \n> > \n> >\n> \n> ______________________________________________\n> R-help@stat.math.ethz.ch mailing list\n> https://stat.ethz.ch/mailman/listinfo/r-help\n> PLEASE do read the posting guide http://www.R-project.org/posting-\n> guide.htmland provide commented, minimal, self-contained, \n> reproducible code.\n>\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}