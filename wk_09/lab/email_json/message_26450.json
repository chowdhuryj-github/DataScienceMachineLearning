{"category": "ham", "to_address": "r-help@stat.math.ethz.ch", "from_address": "Andrew Schuh <aschuh@atmos.colostate.edu>", "subject": "[R] generalized least squares with empirical error covariance matrix", "body": "I have a bayesian hierarchical normal regression model, in which the \nregression coefficients are nested, which I've wrapped into one \nregression framework, y = X %*% beta + e .  I would like to run data \nthrough the model in a filter style (kalman filterish), updating \nregression coefficients at each step new data can be gathered.  After \nthe first filter step, I will need to be able to feed the a non-diagonal \nposterior covariance in for the prior of the next step.  \"gls\" and \"glm\" \nseem to be set up to handle structured error covariances, where mine is \nmore empirical, driven completely by the data.  Explicitly solving w/ \n\"solve\" is really sensitive to small values in the covariance matrix and \nI've only been able to get reliable results at the first step by using \nweighted regression w/ lm().  Am I missing an obvious function for \nlinear regression w/ a correlated  prior on the errors for the updating \nsteps?  Thanks in advance for any advice.\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}