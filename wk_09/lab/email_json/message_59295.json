{"category": "ham", "to_address": "r-help@stat.math.ethz.ch", "from_address": "martin sikora <martin.sikora@upf.edu>", "subject": "[R] speed and looping issues; calculations on big datasets", "body": "dear r users,\n\ni'm a little stuck with the following problem(s), hopefully somebody  \ncan offer some help:\n\ni have data organized in a binary matrix, which can become quite big  \nlike 60 rows x 10^5 columns (they represent SNP genotypes, for some  \nbackground info). what i need to do is the following:\n\nlet's suppose i have a matrix of size n x m. for each of the m  \ncolumns, i want to know the counts of unique rows extended one by one  \nfrom the \"core\" column, for both values at the \"core\" separately and  \nin both directions. maybe better explained with a little example.\n\ndata:\n\n00 0 010\n10 1 001\n11 1 011\n10 0 011\n10 0 010\n\nso the extended unique rows & counts taking e.g. column 3 as \"core\" are:\n\ncol 3 = 0:\nright:\npatterns / counts\n00 / 3\n001 / 3\n0010, 0011 / 2,1\n\nleft:\n00 / 3\n000,001 / 1,2\n\nand that for the other subset ( col3 = 1) as well, then doing the  \nwhole thing again for the next \"core\" column. the reason i need this  \ncounts is that i want to calculate frequencies of the different  \nextended sequences to calculate the probability of drawing two  \nidentical sequences from the core up to an extended position from the  \nwhole set of sequences.\n\nmy main problem is speed of the calculations. i tried different ways  \nsuggested here in the list of getting the counts of the unique rows,  \nall of them using the \"table\" function. both a combination of table \n( do.call( paste, c( as.data.frame( mymatrix) ) ) ) or table( apply \n( mymatrix , 2 , paste , collapse =\"\" ) ) work fine, but are too slow  \nfor bigger matrices that i want to calculate (at least in my not very  \nsophisticated function). then i found a great suggestion here to do a  \nmatrix multiplication with a vector of 2^(0:ncol-1) to convert each  \nrow into a decimal number, and do table on those. this speeds up  \nthings quite nicely, although the problem is that it of course does  \nnot work as soon as i extended for more than 60 columns, because the  \ndecimal numbers get to large to accurately distinguish between a 0  \nand 1 at the smallest digit:\n\n > 2^60+2 == 2^60\n[1] TRUE\n\nanother thing is that so far i could not come up with an idea on how  \nor if it is possible to do this without the loops i am using, one  \nlarge loop for each column in turn as core, and then another loop  \nwithin that extends the rows by growing column numbers. since i am  \nnot the best of programmers (and still quite new to R), i was hoping  \nthat somebody has some advice on doing this calculations in a more  \nelegant and more importantly, fast way.\njust to get the idea, the approach with the matrix multiplication  \ntakes 20s for a 60 x 220 matrix on my macbook pro, which is obviously  \nnot perfect, considering i would like to use this function for  \nmatrices of size 10^2 x 10^5 or even more.\n\nso i would be very thankful for any ideas, suggestions etc to improve  \nthis\n\ncheers\nmartin\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}