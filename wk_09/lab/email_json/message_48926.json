{"category": "ham", "to_address": "R-help@stat.math.ethz.ch", "from_address": "Robert A LaBudde <ral@lcfltd.com>", "subject": "Re: [R] [Not R question]: Better fit for order probit model", "body": "At 09:31 PM 6/15/2007, adschai wrote:\n>I have a model which tries to fit a set of data with 10-level \n>ordered responses. Somehow, in my data, the majority of the \n>observations are from level 6-10 and leave only about 1-5% of total \n>observations contributed to level 1-10. As a result, my model tends \n>to perform badly on points that have lower level than 6.\n>\n>I would like to ask if there's any way to circumvent this problem or \n>not. I was thinking of the followings ideas. But I am opened to any \n>suggestions if you could please.\n>\n>1. Bootstrapping with small size of samples each time. Howevever, in \n>each sample basket, I intentionally sample in such a way that there \n>is a good mix between observations from each level. Then I have to \n>do this many times. But I don't know how to obtain the true standard \n>error of estimated parameters after all bootstrapping has been done. \n>Is it going to be simply the average of all standard errors \n>estimated each time?\n>\n>2. Weighting points with level 1-6 more. But it's unclear to me how \n>to put this weight back to maximum likelihood when estimating \n>parameters. It's unlike OLS where your objective is to minimize \n>error or, if you'd like, a penalty function. But MLE is obviously \n>not a penalty function.\n>\n>3. Do step-wise regression. I will segment the data into two \n>regions, first points with response less than 6 and the rest with \n>those above 6. The first step is a binary regression to determine if \n>the point belongs to which of the two groups. Then in the second \n>step, estimate ordered probit model for each group separately. The \n>question here is then, why I am choosing 6 as a cutting point \n>instead of others?\n>\n>Any suggestions would be really appreciated. Thank you.\n\nYou could do the obvious, and lump categories such as 1-6 or 1-7 \ntogether to make a composite category.\n\nYou don't mention the size of your dataset. If there are 10,000 data, \nyou might live with a 1% category. If you only have 100 data, you \nhave too many categories.\n\nAlso, next time plan your study and training better so that next time \nyour categories are fully utilized. And don't use so many categories. \nPeople have trouble even selecting responses on a 5-level scale.\n================================================================\nRobert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral@lcfltd.com\nLeast Cost Formulations, Ltd.            URL: http://lcfltd.com/\n824 Timberlake Drive                     Tel: 757-467-0954\nVirginia Beach, VA 23464-3239            Fax: 757-467-2947\n\n\"Vere scire est per causas scire\"\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}