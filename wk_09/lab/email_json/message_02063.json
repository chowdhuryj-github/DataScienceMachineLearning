{"category": "ham", "to_address": "\"Wensui Liu\" <liuwensui@gmail.com>", "from_address": "\"Gabor Grothendieck\" <ggrothendieck@gmail.com>", "subject": "Re: [R] Reasons to Use R", "body": "I think SAS was developed at a time when computer memory was\nmuch smaller than it is now and the legacy of that is its better\nusage of computer resources.\n\nOn 4/10/07, Wensui Liu  wrote:\n> Greg,\n> As far as I understand, SAS is more efficient handling large data\n> probably than S+/R. Do you have any idea why?\n>\n> On 4/10/07, Greg Snow  wrote:\n> > > -----Original Message-----\n> > > From: r-help-bounces@stat.math.ethz.ch\n> > > [mailto:r-help-bounces@stat.math.ethz.ch] On Behalf Of\n> > > Bi-Info (http://members.home.nl/bi-info)\n> > > Sent: Monday, April 09, 2007 4:23 PM\n> > > To: Gabor Grothendieck\n> > > Cc: Lorenzo Isella; r-help@stat.math.ethz.ch\n> > > Subject: Re: [R] Reasons to Use R\n> >\n> > [snip]\n> >\n> > > So what's the big deal about S using files instead of memory\n> > > like R. I don't get the point. Isn't there enough swap space\n> > > for S? (Who cares\n> > > anyway: it works, isn't it?) Or are there any problems with S\n> > > and large datasets? I don't get it. You use them, Greg. So\n> > > you might discuss that issue.\n> > >\n> > > Wilfred\n> > >\n> > >\n> >\n> > This is my understanding of the issue (not anything official).\n> >\n> > If you use up all the memory while in R, then the OS will start swapping\n> > memory to disk, but the OS does not know what parts of memory correspond\n> > to which objects, so it is entirely possible that the chunk swapped to\n> > disk contains parts of different data objects, so when you need one of\n> > those objects again, everything needs to be swapped back in.  This is\n> > very inefficient.\n> >\n> > S-PLUS occasionally runs into the same problem, but since it does some\n> > of its own swapping to disk it can be more efficient by swapping single\n> > data objects (data frames, etc.).  Also, since S-PLUS is already saving\n> > everything to disk, it does not actually need to do a full swap, it can\n> > just look and see that a particular data frame has not been used for a\n> > while, know that it is already saved on the disk, and unload it from\n> > memory without having to write it to disk first.\n> >\n> > The g.data package for R has some of this functionality of keeping data\n> > on the disk until needed.\n> >\n> > The better approach for large data sets is to only have some of the data\n> > in memory at a time and to automatically read just the parts that you\n> > need.  So for big datasets it is recommended to have the actual data\n> > stored in a database and use one of the database connection packages to\n> > only read in the subset that you need.  The SQLiteDF package for R is\n> > working on automating this process for R.  There are also the bigdata\n> > module for S-PLUS and the biglm package for R have ways of doing some of\n> > the common analyses using chunks of data at a time.  This idea is not\n> > new.  There was a program in the late 1970s and 80s called Rummage by\n> > Del Scott (I guess technically it still exists, I have a copy on a 5.25\"\n> > floppy somewhere) that used the approach of specify the model you wanted\n> > to fit first, then specify the data file.  Rummage would then figure out\n> > which sufficient statistics were needed and read the data in chunks,\n> > compute the sufficient statistics on the fly, and not keep more than a\n> > couple of lines of the data in memory at once.  Unfortunately it did not\n> > have much of a user interface, so when memory was cheap and datasets\n> > only medium sized it did not compete well, I guess it was just a bit too\n> > ahead of its time.\n> >\n> > Hope this helps,\n> >\n> >\n> >\n> > --\n> > Gregory (Greg) L. Snow Ph.D.\n> > Statistical Data Center\n> > Intermountain Healthcare\n> > greg.snow@intermountainmail.org\n> > (801) 408-8111\n> >\n> > ______________________________________________\n> > R-help@stat.math.ethz.ch mailing list\n> > https://stat.ethz.ch/mailman/listinfo/r-help\n> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html\n> > and provide commented, minimal, self-contained, reproducible code.\n> >\n>\n>\n> --\n> WenSui Liu\n> A lousy statistician who happens to know a little programming\n> (http://spaces.msn.com/statcompute/blog)\n>\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}