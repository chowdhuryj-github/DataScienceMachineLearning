{"category": "ham", "to_address": "\"'Viechtbauer Wolfgang \\(STAT\\)'\" <Wolfgang.Viechtbauer@STAT.unimaas.nl>", "from_address": "\"John Fox\" <jfox@mcmaster.ca>", "subject": "Re: [R] Boostrap p-value in regression [indirectly related to R]", "body": "Dear Wolfgang,\n\nI agree that it's preferable to compute the two-sided p-value without\nassuming symmetry. Another, equivalent, way of thinking about this is to use\nt^2 for the two-sided test in place of t.\n\nBTW, the formula used in my appendix (for the one-sided p-value) is from\nDavison and Hinkley, I believe, and differs trivially from the one in Efron\nand Tibshirani.\n\nRegards,\n John\n\n--------------------------------\nJohn Fox, Professor\nDepartment of Sociology\nMcMaster University\nHamilton, Ontario\nCanada L8S 4M4\n905-525-9140x23604\nhttp://socserv.mcmaster.ca/jfox \n-------------------------------- \n\n> -----Original Message-----\n> From: r-help-bounces@stat.math.ethz.ch \n> [mailto:r-help-bounces@stat.math.ethz.ch] On Behalf Of \n> Viechtbauer Wolfgang (STAT)\n> Sent: Monday, May 21, 2007 10:41 AM\n> To: r-help@stat.math.ethz.ch\n> Subject: [R] Boostrap p-value in regression [indirectly related to R]\n> \n> Hello All,\n> \n> Despite my preference for reporting confidence intervals, I \n> need to obtain a p-value for a hypothesis test in the context \n> of regression using bootstrapping. I have read John Fox's \n> chapter on bootstrapping regression models and have consulted \n> Efron & Tibshirani's \"An Introduction to the Bootstrap\" but I \n> just wanted to ask the experts here for some feedback to make \n> sure that I am not doing something wrong.\n> \n> Let's take a simplified example where the model includes one \n> independent variable and the idea is to test H0: beta1 = 0 \n> versus Ha: beta1 != 0.\n> \n> ########################################################\n> \n> ### generate some sample data\n> \n> n  <- 50\n> xi <- runif(n, min=1, max=5)\n> yi <- 0 + 0.2 * xi + rnorm(n, mean=0, sd=1)\n> \n> ### fit simple regression model\n> \n> mod <- lm(yi ~ xi)\n> summary(mod)\n> b1  <- coef(mod)[2]\n> t1  <- coef(mod)[2] / coef(summary(mod))[2,2]\n> \n> ### 1000 bootstrap replications using (X,Y)-pair resampling\n> \n> t1.star <- rep(NA,1000)\n> \n> for (i in 1:1000) {\n> \n>   ids        <- sample(1:n, replace=TRUE)\n>   newyi      <- yi[ids]\n>   newxi      <- xi[ids]  \n>   mod        <- lm(newyi ~ newxi)\n>   t1.star[i] <- ( coef(mod)[2] - b1) / coef(summary(mod))[2,2]\n> \n> }\n> \n> ### get bootstrap p-value\n> \n> hist(t1.star, nclass=40)\n> abline(v=t1, lwd=3)\n> abline(v=-1*t1, lwd=3)\n> 2 * mean( t1.star > abs(t1) )\n> \n> ########################################################\n> \n> As suggested in the chapter on bootstrapping regression \n> models by John Fox, the bootstrap p-value is 2 times the \n> proportion of bootstrap t-values (with b1 subtracted so that \n> we get the distribution under H0) larger than the absolute \n> value of the actual t-value observed in the data. \n> \n> Doesn't this assume that the bootstrap sampling distribution \n> is symmetric? And if yes, would it then not be more reasonable to\n> calculate:\n> \n> mean( abs(t1.star) > abs(t1) )\n> \n> or in words: the number of bootstrap t-values that are more \n> extreme on either side of the bootstrap distribution than the \n> actual t-value observed?\n> \n> Any suggestions or comments would be appreciated!\n> \n> --\n> Wolfgang Viechtbauer\n>  Department of Methodology and Statistics  University of \n> Maastricht, The Netherlands  http://www.wvbauer.com\n> \n> ______________________________________________\n> R-help@stat.math.ethz.ch mailing list\n> https://stat.ethz.ch/mailman/listinfo/r-help\n> PLEASE do read the posting guide \n> http://www.R-project.org/posting-guide.html\n> and provide commented, minimal, self-contained, reproducible code.\n>\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}