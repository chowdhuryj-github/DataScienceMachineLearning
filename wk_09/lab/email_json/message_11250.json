{"category": "ham", "to_address": "hadley wickham <h.wickham@gmail.com>", "from_address": "Iestyn Lewis <ilewis@pharm.emory.edu>", "subject": "Re: [R] Fastest way to repeatedly subset a data frame?", "body": "Good tip - an Rprof trace over my real data set resulted in a file \nfilled with:\n\npmatch [.data.frame [ FUN lapply\npmatch [.data.frame [ FUN lapply\npmatch [.data.frame [ FUN lapply\npmatch [.data.frame [ FUN lapply\npmatch [.data.frame [ FUN lapply\n...\nwith very few other calls in there.  pmatch seems to be the string \nsearch function, so I'm guessing there's no hashing going on, or not \nvery good hashing.\n\nI'll let you know how the environment option works - the Bioconductor \nproject seems to make extensive use of it, so I'm guessing it's the way \nto go.\n\nIestyn\n\nhadley wickham wrote:\n>> But... it's not any faster, which is worrisome to me because it seems\n>> like your code uses rownames and would take advantage of the hashing\n>> potential of named items.\n>\n> I'm pretty sure it will use a hash to access the specified rows.\n> Before you pursue an environment based solution, you might want to\n> profile the code to check that the hashing is actually the slowest\n> part - I suspect creating all new data.frames is taking the most time.\n>\n> Hadley\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}