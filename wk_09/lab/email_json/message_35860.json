{"category": "ham", "to_address": "Deepankar Basu <basu.15@osu.edu>", "from_address": "Prof Brian Ripley <ripley@stats.ox.ac.uk>", "subject": "Re: [R] Problem with numerical integration and optimization with\n BFGS", "body": "You are trying to use a derivative-based optimization method without \nsupplying derivatives.  This will use numerical approoximations to the \nderivatives, and your objective function will not be suitable as it is \ninternally using adaptive numerical quadrature and hence is probably not \nclose enough to a differentiable function (it may well have steps).\n\nI believe you can integrate analytically (the answer will involve pnorm), \nand that you can also find analytical derivatives.\n\nUsing (each of) numerical optimization and integration is a craft, and it \nseems you need to know more about it.  The references on ?optim are too \nadvanced I guess, so you could start with Chapter 16 of MASS and its \nreferences.\n\nOn Thu, 24 May 2007, Deepankar Basu wrote:\n\n> Hi R users,\n>\n> I have a couple of questions about some problems that I am facing with\n> regard to numerical integration and optimization of likelihood\n> functions. Let me provide a little background information: I am trying\n> to do maximum likelihood estimation of an econometric model that I have\n> developed recently. I estimate the parameters of the model using the\n> monthly US unemployment rate series obtained from the Federal Reserve\n> Bank of St. Louis. (The data is freely available from their web-based\n> database called FRED-II).\n>\n> For my model, the likelihood function for each observation is the sum of\n> three integrals. The integrand in each of these integrals is of the\n> following form:\n>\n> A*exp(B+C*x-D*x^2)\n>\n> where A, B, C and D are constants, exp() is the exponential function and\n> x is the variable of integration. The constants A and D are always\n> positive; B is always negative, while there is no a priori knowledge\n> about the sign of C. All the constants are finite.\n>\n> Of the three integrals, one has finite limits while the other two have\n> the following limits:\n>\n> lower = -Inf\n> upper = some finite number (details can be found in the code below)\n\nTry integrating that analytically by change of variable to a normal CDF.\n\n\n> My problem is the following: when I try to maximize the log-likelihood\n> function using \"optim\" with method \"BFGS\", I get the following error\n> message (about the second integral):\n>\n>> out <- optim(alpha.start, LLK, gr=NULL, method=\"BFGS\", y=urate$y)\n> Error in integrate(f3, lower = -Inf, upper = upr2) :\n>        the integral is probably divergent\n>\n> Since I know that all the three integrals are convergent, I do not\n> understand why I am getting this error message. My first question: can\n> someone explain what mistake I am making?\n>\n> What is even more intriguing is that when I use the default method\n> (Nelder-Mead) in \"optim\" instead of BFGS, I do not get any such error\n> message. Since both methods (Nelder-Mead and BFGS) will need to evaluate\n> the integrals, my second question is: why this difference?\n>\n> Below, I am providing the code that I use. Any help will be greatly\n> appreciated.\n>\n>\n> Deepankar\n>\n>\n> ************ CODE START *******************\n>\n>\n>\n> #############################\n> # COMPUTING THE LOGLIKELIHOOD\n> # USING NUMERICAL INTEGRALS\n> #############################\n>\n> LLK <- function(alpha, y) {\n>\n>  n <- length(y)\n>  lglik <- numeric(n) # TO BE SUMMED LATER TO GET THE LOGLIKELIHOOD\n>\n>           lambda <- numeric(n-1)    # GENERATING *lstar*\n>           for (i in 1:(n-1)) {      # TO USE IN THE\n>           lambda[i] <- y[i+1]/y[i]  # RE-PARAMETRIZATION BELOW\n>           }\n>           lstar <- (min(lambda)-0.01)\n>\n>\n> # NOTE RE-PARAMETRIZATION\n> # THESE RESTRICTIONS EMERGE FROM THE MODEL\n>\n>  muep <- alpha[1]                                      # NO RESTRICTION\n>  sigep <-  0.01 + exp(alpha[2])                        # greater than\n> 0.01\n>  sigeta <- 0.01 + exp(alpha[3])                        # greater than\n> 0.01\n>  rho2 <- 0.8*sin(alpha[4])                             # between -0.8\n> and 0.8\n>  rho1 <- lstar*abs(alpha[5])/(1+abs(alpha[5]))         # between 0 and\n> lstar\n>  delta <- 0.01 + exp(alpha[6])                         # greater than\n> 0.01\n>\n>\n> ##########################################\n> # THE THREE FUNCTIONS TO INTEGRATE\n> # FOR COMPUTING THE LOGLIKELIHOOD\n> ##########################################\n>\n>  denom <- 2*pi*sigep*sigeta*(sqrt(1-rho2^2)) # A CONSTANT TO BE USED\n>                                              # FOR DEFINING THE\n>                                              # THREE FUNCTIONS\n>\n>\n>  f1 <- function(z1) {  # FIRST FUNCTION\n>\n>       b11 <- ((z1-muep)^2)/((-2)*(1-rho2^2)*(sigep^2))\n>       b12 <-\n> (rho2*(z1-muep)*(y[i]-y[i-1]+delta))/((1-rho2^2)*sigep*sigeta)\n>       b13 <- ((y[i]-y[i-1]+delta)^2)/((-2)*(1-rho2^2)*(sigeta^2))\n>\n>     return((exp(b11+b12+b13))/denom)\n>  }\n>\n>  f3 <- function(z3) { # SECOND FUNCTION\n>\n>       b31 <- ((y[i]-rho1*y[i-1]-muep)^2)/((-2)*(1-rho2^2)*(sigep^2))\n>       b32 <-\n> (rho2*(y[i]-rho1*y[i-1]-muep)*z3)/((1-rho2^2)*sigep*sigeta)\n>       b33 <- ((z3)^2)/((-2)*(1-rho2^2)*(sigeta^2))\n>\n>     return((exp(b31+b32+b33))/denom)\n>  }\n>\n>  f5 <- function(z5) { # THIRD FUNCTION\n>\n>       b51 <- ((-y[i]+rho1*y[i-1]-muep)^2)/((-2)*(1-rho2^2)*sigep^2)\n>       b52 <-\n> (rho2*(-y[i]+rho1*y[i-1]-muep)*(z5))/((1-rho2^2)*sigep*sigeta)\n>       b53 <- ((z5)^2)/((-2)*(1-rho2^2)*(sigeta^2))\n>\n>     return((exp(b51+b52+b53))/denom)\n>  }\n>\n>\n>  for (i in 2:n) {   # START FOR LOOP\n>\n>        upr1 <- (y[i]-rho1*y[i-1])\n>        upr2 <- (y[i]-y[i-1]+delta)\n>\n>     # INTEGRATING THE THREE FUNCTIONS\n>      out1 <- integrate(f1, lower = (-1)*upr1, upper = upr1)\n>      out3 <- integrate(f3, lower = -Inf, upper = upr2)\n>      out5 <- integrate(f5, lower= -Inf, upper = upr2)\n>\n>       pdf <- (out1$val + out3$val + out5$val)\n>\n>     lglik[i] <- log(pdf) # LOGLIKELIHOOD FOR OBSERVATION i\n>\n>     }               # END FOR LOOP\n>\n> return(-sum(lglik)) # RETURNING NEGATIVE OF THE LOGLIKELIHOOD\n>                     # BECAUSE optim DOES MINIMIZATION BY DEFAULT\n> }\n>\n> ***************** CODE ENDS *********************************\n>\n> Then I use:\n>\n>> urate <- read.table(\"~/Desktop/UNRATE1.txt\", header=TRUE) # DATA\n>> alpha.start <- c(0.5, -1, -1, 0, 1, -1) # STARTING VALUES\n>> out <- optim(alpha.start, LLK, gr=NULL, y=urate$y) # THIS GIVES NO\n> ERROR\n>\n> or\n>\n>> out <- optim(alpha.start, LLK, gr=NULL, method=\"BFGS\", y=urate$y)\n> Error in integrate(f3, lower = -Inf, upper = upr2) :\n>        the integral is probably divergent\n>\n> ______________________________________________\n> R-help@stat.math.ethz.ch mailing list\n> https://stat.ethz.ch/mailman/listinfo/r-help\n> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html\n> and provide commented, minimal, self-contained, reproducible code.\n>\n\n-- \nBrian D. Ripley,                  ripley@stats.ox.ac.uk\nProfessor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/\nUniversity of Oxford,             Tel:  +44 1865 272861 (self)\n1 South Parks Road,                     +44 1865 272866 (PA)\nOxford OX1 3TG, UK                Fax:  +44 1865 272595\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}