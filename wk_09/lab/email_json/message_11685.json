{"category": "ham", "to_address": "r-help@stat.math.ethz.ch", "from_address": "Owe Jessen <jessen@econinfo.de>", "subject": "Re: [R] software comparison", "body": "Ben Bolker schrieb:\n> Philippe Grosjean  sciviews.org> writes:\n>\n>   \n>> Hello,\n>>\n>> For a paper published in 2007, and submitted in April 2005, this is \n>> still surprising. If I my calculation is correct, in 2004, they would \n>> have used R 2.2.x, or something,... not 1.9.1?\n>>\n>> Anyway, does someone know if there is a chance 2.5.0 provides some \n>> improvements in some of the \"difficult cases\" for R 1.9.1 (for instance, \n>> improvement of the algorithms for calculating autocorrelation, ANOVA, \n>> linear regression or non linear regression)?\n>>\n>>     \n>\n>   I did a bit of testing (with 2.6.0 unstable).\n> Two of the tests that R 1.9.1 did worst on were\n> ANOVAs of NIST data sets SiRstv and AgWt \n> (LREs listed in the paper for these tests are\n>  5.7 and 6.7 respectively, compared\n> with SAS 9.1's 12.7 and 8.8, Splus 6.2's 13.4\n> and 9.7).\n>\n>   The code below produces LREs of\n> 13.3 for SiRstv and 9.18 for AgWt -- close to Splus\n> 6.2, better than SAS.\n>\n>   If anyone has a whole zoo of R versions lying around\n> they could go back and try this code on them ...\n>\n>   Ben Bolker\n>\n>\n>   \nThe results seem to be rather stable, I get identical values on R 2.4.1\nand 2.2.1\n\nHTH\n\nOwe Jessen\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}