{"category": "ham", "to_address": "James Keenan <jkeen@verizon.net>", "from_address": "Will Coleda <will@coleda.com>", "subject": "Re: failing test for #42360: Parrot::Revision unit tests", "body": "I had similar failures here where I got '0' vs. some other number.\n\n$ prove -v t/postconfigure/03-revision.t\nt/postconfigure/03-revision....1..7\nok 1 - use Cwd;\nok 2 - use File::Copy;\nok 3 - use File::Temp;\nok 4 - current revision is all numeric\nok 5 - current revision is all numeric\n\n#   Failed test 'current and config are identical'\n#   at t/postconfigure/03-revision.t line 32.\nnot ok 6 - current and config are identical\n#          got: '0'\n#     expected: '18442'\nok 7 - Completed all tests in t/postconfigure/03-revision.t\n# Looks like you failed 1 test of 7.\ndubious\n         Test returned status 1 (wstat 256, 0x100)\nDIED. FAILED test 6\n         Failed 1/7 tests, 85.71% okay\nFailed Test                   Stat Wstat Total Fail  List of Failed\n------------------------------------------------------------------------ \n-------\nt/postconfigure/03-revision.t    1   256     7    1  6\nFailed 1/1 test scripts. 1/7 subtests failed.\nFiles=1, Tests=7,  0 wallclock secs ( 0.06 cusr +  0.03 csys =  0.09  \nCPU)\nFailed 1/1 test programs. 1/7 subtests failed.\n\n\nOn May 8, 2007, at 8:46 PM, James Keenan wrote:\n\n> Allison Randal wrote:\n> > This test seems to expect that the current revision and the revision\n> > where I last ran Configure.pl are always the same. Why?\n> >\n> > ------\n> > allison@ezet:~/projects/svn/parrot$ prove t/postconfigure/03- \n> revision.t\n> > t/postconfigure/03-revision....ok 4/7#     Failed test\n> > (t/postconfigure/03-revision.t at line 32)\n> > t/postconfigure/03-revision....ok 5/7#          got: '18472'\n> > #     expected: '18469'\n> > t/postconfigure/03-revision....NOK 6# Looks like you failed 1  \n> tests of 7.\n> > t/postconfigure/03-revision....dubious\n> >         Test returned status 1 (wstat 256, 0x100)\n> > DIED. FAILED test 6\n> >         Failed 1/7 tests, 85.71% okay\n> > Failed Test                   Stat Wstat Total Fail  Failed  List  \n> of Failed\n> >  \n> ---------------------------------------------------------------------- \n> ---------\n> >\n> > t/postconfigure/03-revision.t    1   256     7    1  14.29%  6\n> > Failed 1/1 test scripts, 0.00% okay. 1/7 subtests failed, 85.71%  \n> okay.\n>\n> Please see my response of a few minutes ago to a similar question  \n> from Andy Spieherty.  Can you answer the same sort of questions I  \n> asked in that email?  Also, can you send the output of 'prove -v'  \n> on the failing test?\n>\n> Thank you very much.\n> kid51\n>\n\n--\nWill \"Coke\" Coleda\nwill@coleda.com\n\n\n"}