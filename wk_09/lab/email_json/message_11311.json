{"category": "ham", "to_address": "Iestyn Lewis <ilewis@pharm.emory.edu>", "from_address": "Tony Plate <tplate@acm.org>", "subject": "Re: [R] Fastest way to repeatedly subset a data frame?", "body": "This type of information about speeds of various techniques can really \nonly be found out by trying things out, especially because R-core has \nrecently made a fair number of improvements to some of the underlying \ncode in R.  That's part of the reason I put these tests together -- I \nwanted to know for myself what sort of speed differences there was now \namong the various approaches.\n\n-- Tony Plate\n\nIestyn Lewis wrote:\n> This is fantastic.  I just tested the first match() method and it is \n> acceptably fast.  I'll look into some of the even better methods \n> later.   Thank you for taking the time to put this together.\n> \n> Is this kind of optimization information on the web anywhere?  I can \n> imagine that a lot of people have slow sets of commands that could be \n> optimized with this kind of knowledge. \n> \n> Thank you so much,\n> \n> Iestyn\n> \n> Tony Plate wrote:\n>> Here's some timings on seemingly minor variations of data structure \n>> showing timings ranging by a factor of 100 (factor of 3 if the worst \n>> is omitted).  One of the keys is to avoid use of the partial string \n>> match that happens with ordinary data frame subscripting.\n>>\n>> -- Tony Plate\n>>\n>>> n <- 10000 # number of rows in data frame\n>>> k <- 500   # number of vectors in indexing list\n>>> # use a data frame with regular row names and id as factor (defaults \n>> for data.frame)\n>>> df <- data.frame(id=paste(\"ID\", seq(len=n), sep=\"\"), \n>> result=seq(len=n), stringsAsFactors=TRUE)\n>>> object.size(df)\n>> [1] 440648\n>>> df[1:3,,drop=FALSE]\n>>    id result\n>> 1 ID1      1\n>> 2 ID2      2\n>> 3 ID3      3\n>>> set.seed(1)\n>>> ids <- lapply(seq(k), function(i) paste(\"ID\", sample(n, \n>> size=sample(seq(ceiling(n/1000), n/2, 1))), sep=\"\"))\n>>> sum(sapply(ids, length))\n>> [1] 1263508\n>>> system.time(lapply(ids, function(i) df[match(i, df$id),,drop=FALSE]))\n>>    user  system elapsed\n>>    3.00    0.00    3.03\n>>> # use a data frame with automatic row names (should be low overhead) \n>> and id as factor\n>>> df <- data.frame(id=paste(\"ID\", seq(len=n), sep=\"\"), \n>> result=seq(len=n), row.names=NULL, stringsAsFactors=TRUE)\n>>> object.size(df)\n>> [1] 440648\n>>> df[1:3,,drop=FALSE]\n>>    id result\n>> 1 ID1      1\n>> 2 ID2      2\n>> 3 ID3      3\n>>> set.seed(1)\n>>> ids <- lapply(seq(k), function(i) paste(\"ID\", sample(n, \n>> size=sample(seq(ceiling(n/1000), n/2, 1))), sep=\"\"))\n>>> sum(sapply(ids, length))\n>> [1] 1263508\n>>> system.time(lapply(ids, function(i) df[match(i, df$id),,drop=FALSE]))\n>>    user  system elapsed\n>>    2.68    0.00    2.70\n>>> # use a data frame with automatic row names (should be low overhead) \n>> and id as character\n>>> df <- data.frame(id=paste(\"ID\", seq(len=n), sep=\"\"), \n>> result=seq(len=n), row.names=NULL, stringsAsFactors=FALSE)\n>>> object.size(df)\n>> [1] 400448\n>>> df[1:3,,drop=FALSE]\n>>    id result\n>> 1 ID1      1\n>> 2 ID2      2\n>> 3 ID3      3\n>>> set.seed(1)\n>>> ids <- lapply(seq(k), function(i) paste(\"ID\", sample(n, \n>> size=sample(seq(ceiling(n/1000), n/2, 1))), sep=\"\"))\n>>> sum(sapply(ids, length))\n>> [1] 1263508\n>>> system.time(lapply(ids, function(i) df[match(i, df$id),,drop=FALSE]))\n>>    user  system elapsed\n>>    1.54    0.00    1.59\n>>> # use a data frame with ids as the row names & subscripting for \n>> matching (should be high overhead)\n>>> df <- data.frame(id=paste(\"ID\", seq(len=n), sep=\"\"), \n>> result=seq(len=n), row.names=\"id\")\n>>> object.size(df)\n>> [1] 400384\n>>> df[1:3,,drop=FALSE]\n>>     result\n>> ID1      1\n>> ID2      2\n>> ID3      3\n>>> set.seed(1)\n>>> ids <- lapply(seq(k), function(i) paste(\"ID\", sample(n, \n>> size=sample(seq(ceiling(n/1000), n/2, 1))), sep=\"\"))\n>>> sum(sapply(ids, length))\n>> [1] 1263508\n>>> system.time(lapply(ids, function(i) df[i,,drop=FALSE]))\n>>    user  system elapsed\n>>  109.15    0.04  111.28\n>>> # use a data frame with ids as the row names & match()\n>>> df <- data.frame(id=paste(\"ID\", seq(len=n), sep=\"\"), \n>> result=seq(len=n), row.names=\"id\")\n>>> object.size(df)\n>> [1] 400384\n>>> df[1:3,,drop=FALSE]\n>>     result\n>> ID1      1\n>> ID2      2\n>> ID3      3\n>>> set.seed(1)\n>>> ids <- lapply(seq(k), function(i) paste(\"ID\", sample(n, \n>> size=sample(seq(ceiling(n/1000), n/2, 1))), sep=\"\"))\n>>> sum(sapply(ids, length))\n>> [1] 1263508\n>>> system.time(lapply(ids, function(i) df[match(i, \n>> rownames(df)),,drop=FALSE]))\n>>    user  system elapsed\n>>    1.53    0.00    1.58\n>>> # use a named numeric vector to store the same data as was stored in \n>> the data frame\n>>> x <- seq(len=n)\n>>> names(x) <- paste(\"ID\", seq(len=n), sep=\"\")\n>>> object.size(x)\n>> [1] 400104\n>>> x[1:3]\n>> ID1 ID2 ID3\n>>   1   2   3\n>>> set.seed(1)\n>>> ids <- lapply(seq(k), function(i) paste(\"ID\", sample(n, \n>> size=sample(seq(ceiling(n/1000), n/2, 1))), sep=\"\"))\n>>> sum(sapply(ids, length))\n>> [1] 1263508\n>>> system.time(lapply(ids, function(i) x[match(i, names(x))]))\n>>    user  system elapsed\n>>    1.14    0.05    1.19\n>>\n>>\n>>\n>>\n>> Iestyn Lewis wrote:\n>>> Good tip - an Rprof trace over my real data set resulted in a file \n>>> filled with:\n>>>\n>>> pmatch [.data.frame [ FUN lapply\n>>> pmatch [.data.frame [ FUN lapply\n>>> pmatch [.data.frame [ FUN lapply\n>>> pmatch [.data.frame [ FUN lapply\n>>> pmatch [.data.frame [ FUN lapply\n>>> ...\n>>> with very few other calls in there.  pmatch seems to be the string \n>>> search function, so I'm guessing there's no hashing going on, or not \n>>> very good hashing.\n>>>\n>>> I'll let you know how the environment option works - the Bioconductor \n>>> project seems to make extensive use of it, so I'm guessing it's the \n>>> way to go.\n>>>\n>>> Iestyn\n>>>\n>>> hadley wickham wrote:\n>>>>> But... it's not any faster, which is worrisome to me because it seems\n>>>>> like your code uses rownames and would take advantage of the hashing\n>>>>> potential of named items.\n>>>> I'm pretty sure it will use a hash to access the specified rows.\n>>>> Before you pursue an environment based solution, you might want to\n>>>> profile the code to check that the hashing is actually the slowest\n>>>> part - I suspect creating all new data.frames is taking the most time.\n>>>>\n>>>> Hadley\n>>> ______________________________________________\n>>> R-help@stat.math.ethz.ch mailing list\n>>> https://stat.ethz.ch/mailman/listinfo/r-help\n>>> PLEASE do read the posting guide \n>>> http://www.R-project.org/posting-guide.html\n>>> and provide commented, minimal, self-contained, reproducible code.\n>>>\n> \n> ______________________________________________\n> R-help@stat.math.ethz.ch mailing list\n> https://stat.ethz.ch/mailman/listinfo/r-help\n> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html\n> and provide commented, minimal, self-contained, reproducible code.\n>\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}