{"category": "ham", "to_address": "\"'Deepankar Basu'\" <basu.15@osu.edu>,\n   \"'Prof Brian Ripley'\" <ripley@stats.ox.ac.uk>", "from_address": "\"Ravi Varadhan\" <rvaradhan@jhmi.edu>", "subject": "Re: [R] Problem with numerical integration and\n\toptimization\twith\tBFGS", "body": "Deepankar,\n\nIf the problem seems to be in the evaluation of numerical quadrature part,\nyou might want to try quadrature methods that are better suited to\nintegrands with strong peaks.  The traditional Gaussian quadrature methods,\neven their adaptive versions such as Gauss-Kronrod, are not best suited for\nintegrating because they do not explicitly account for the \"peakedness\" of\nthe integrand, and hence can be inefficient and inaccurate. See the article\nbelow:\nhttp://citeseer.ist.psu.edu/cache/papers/cs/18996/http:zSzzSzwww.sci.wsu.edu\nzSzmathzSzfacultyzSzgenzzSzpaperszSzmvn.pdf/genz92numerical.pdf\n\nAlan Genz has worked on this problem a lot and has a number of computational\ntools available. I used some of them when I was working on computing Bayes\nfactors for binomial regression models with different link functions.  If\nyou are interested, check the following:\n\nhttp://www.math.wsu.edu/faculty/genz/software/software.html.\n\nFor your immediate needs, there is an R package called \"mnormt\" that has a\nfunction for computing integrals under a multivariate normal (and\nmultivariate t) densities, which is actually based on Genz's Fortran\nroutines.  You could try that.\n\nRavi.\n\n\n----------------------------------------------------------------------------\n-------\n\nRavi Varadhan, Ph.D.\n\nAssistant Professor, The Center on Aging and Health\n\nDivision of Geriatric Medicine and Gerontology \n\nJohns Hopkins University\n\nPh: (410) 502-2619\n\nFax: (410) 614-9625\n\nEmail: rvaradhan@jhmi.edu\n\nWebpage:  http://www.jhsph.edu/agingandhealth/People/Faculty/Varadhan.html\n\n \n\n----------------------------------------------------------------------------\n--------\n\n\n-----Original Message-----\nFrom: r-help-bounces@stat.math.ethz.ch\n[mailto:r-help-bounces@stat.math.ethz.ch] On Behalf Of Deepankar Basu\nSent: Friday, May 25, 2007 12:02 AM\nTo: Prof Brian Ripley\nCc: r-help@stat.math.ethz.ch\nSubject: Re: [R] Problem with numerical integration and optimization with\nBFGS\n\nProf. Ripley,\n\nThe code that I provided with my question of course does not contain\ncode for the derivatives; but I am supplying analytical derivatives in\nmy full program. I did not include that code with my question because\nthat would have added about 200 more lines of code without adding any\nnew information relevant for my question. The problem that I had pointed\nto occurs whether I provide analytical derivatives or not to the\noptimization routine. And the problem was that when I use the \"BFGS\"\nmethod in optim, I get an error message saying that the integrals are\nprobably divergent; I know, on the other hand, that the integrals are\nconvergent. The same problem does not arise when I instead use the\nNelder-Mead method in optim.\n\nYour suggestion that the expression can be analytically integrated\n(which will involve \"pnorm\") might be correct though I do not see how to\ndo that. The integrands are the bivariate normal density functions with\none variable replaced by known quantities while I integrate over the\nsecond. \n\nFor instance, the first integral is as follows: the integrand is the\nbivariate normal density function (with general covariance matrix) where\nthe second variable has been replaced by \ny[i] - rho1*y[i-1] + delta \nand I integrate over the first variable; the range of integration is\nlower=-y[i]+rho1*y[i-1]\nupper=y[i]-rho1*y[i-1]\n\nThe other two integrals are very similar. It would be of great help if\nyou could point out how to integrate the expressions analytically using\n\"pnorm\".\n\nThanks.\nDeepankar\n\n\nOn Fri, 2007-05-25 at 04:22 +0100, Prof Brian Ripley wrote:\n> You are trying to use a derivative-based optimization method without \n> supplying derivatives.  This will use numerical approoximations to the \n> derivatives, and your objective function will not be suitable as it is \n> internally using adaptive numerical quadrature and hence is probably not \n> close enough to a differentiable function (it may well have steps).\n> \n> I believe you can integrate analytically (the answer will involve pnorm), \n> and that you can also find analytical derivatives.\n> \n> Using (each of) numerical optimization and integration is a craft, and it \n> seems you need to know more about it.  The references on ?optim are too \n> advanced I guess, so you could start with Chapter 16 of MASS and its \n> references.\n> \n> On Thu, 24 May 2007, Deepankar Basu wrote:\n> \n> > Hi R users,\n> >\n> > I have a couple of questions about some problems that I am facing with\n> > regard to numerical integration and optimization of likelihood\n> > functions. Let me provide a little background information: I am trying\n> > to do maximum likelihood estimation of an econometric model that I have\n> > developed recently. I estimate the parameters of the model using the\n> > monthly US unemployment rate series obtained from the Federal Reserve\n> > Bank of St. Louis. (The data is freely available from their web-based\n> > database called FRED-II).\n> >\n> > For my model, the likelihood function for each observation is the sum of\n> > three integrals. The integrand in each of these integrals is of the\n> > following form:\n> >\n> > A*exp(B+C*x-D*x^2)\n> >\n> > where A, B, C and D are constants, exp() is the exponential function and\n> > x is the variable of integration. The constants A and D are always\n> > positive; B is always negative, while there is no a priori knowledge\n> > about the sign of C. All the constants are finite.\n> >\n> > Of the three integrals, one has finite limits while the other two have\n> > the following limits:\n> >\n> > lower = -Inf\n> > upper = some finite number (details can be found in the code below)\n> \n> Try integrating that analytically by change of variable to a normal CDF.\n> \n> \n> > My problem is the following: when I try to maximize the log-likelihood\n> > function using \"optim\" with method \"BFGS\", I get the following error\n> > message (about the second integral):\n> >\n> >> out <- optim(alpha.start, LLK, gr=NULL, method=\"BFGS\", y=urate$y)\n> > Error in integrate(f3, lower = -Inf, upper = upr2) :\n> >        the integral is probably divergent\n> >\n> > Since I know that all the three integrals are convergent, I do not\n> > understand why I am getting this error message. My first question: can\n> > someone explain what mistake I am making?\n> >\n> > What is even more intriguing is that when I use the default method\n> > (Nelder-Mead) in \"optim\" instead of BFGS, I do not get any such error\n> > message. Since both methods (Nelder-Mead and BFGS) will need to evaluate\n> > the integrals, my second question is: why this difference?\n> >\n> > Below, I am providing the code that I use. Any help will be greatly\n> > appreciated.\n> >\n> >\n> > Deepankar\n> >\n> >\n> > ************ CODE START *******************\n> >\n> >\n> >\n> > #############################\n> > # COMPUTING THE LOGLIKELIHOOD\n> > # USING NUMERICAL INTEGRALS\n> > #############################\n> >\n> > LLK <- function(alpha, y) {\n> >\n> >  n <- length(y)\n> >  lglik <- numeric(n) # TO BE SUMMED LATER TO GET THE LOGLIKELIHOOD\n> >\n> >           lambda <- numeric(n-1)    # GENERATING *lstar*\n> >           for (i in 1:(n-1)) {      # TO USE IN THE\n> >           lambda[i] <- y[i+1]/y[i]  # RE-PARAMETRIZATION BELOW\n> >           }\n> >           lstar <- (min(lambda)-0.01)\n> >\n> >\n> > # NOTE RE-PARAMETRIZATION\n> > # THESE RESTRICTIONS EMERGE FROM THE MODEL\n> >\n> >  muep <- alpha[1]                                      # NO RESTRICTION\n> >  sigep <-  0.01 + exp(alpha[2])                        # greater than\n> > 0.01\n> >  sigeta <- 0.01 + exp(alpha[3])                        # greater than\n> > 0.01\n> >  rho2 <- 0.8*sin(alpha[4])                             # between -0.8\n> > and 0.8\n> >  rho1 <- lstar*abs(alpha[5])/(1+abs(alpha[5]))         # between 0 and\n> > lstar\n> >  delta <- 0.01 + exp(alpha[6])                         # greater than\n> > 0.01\n> >\n> >\n> > ##########################################\n> > # THE THREE FUNCTIONS TO INTEGRATE\n> > # FOR COMPUTING THE LOGLIKELIHOOD\n> > ##########################################\n> >\n> >  denom <- 2*pi*sigep*sigeta*(sqrt(1-rho2^2)) # A CONSTANT TO BE USED\n> >                                              # FOR DEFINING THE\n> >                                              # THREE FUNCTIONS\n> >\n> >\n> >  f1 <- function(z1) {  # FIRST FUNCTION\n> >\n> >       b11 <- ((z1-muep)^2)/((-2)*(1-rho2^2)*(sigep^2))\n> >       b12 <-\n> > (rho2*(z1-muep)*(y[i]-y[i-1]+delta))/((1-rho2^2)*sigep*sigeta)\n> >       b13 <- ((y[i]-y[i-1]+delta)^2)/((-2)*(1-rho2^2)*(sigeta^2))\n> >\n> >     return((exp(b11+b12+b13))/denom)\n> >  }\n> >\n> >  f3 <- function(z3) { # SECOND FUNCTION\n> >\n> >       b31 <- ((y[i]-rho1*y[i-1]-muep)^2)/((-2)*(1-rho2^2)*(sigep^2))\n> >       b32 <-\n> > (rho2*(y[i]-rho1*y[i-1]-muep)*z3)/((1-rho2^2)*sigep*sigeta)\n> >       b33 <- ((z3)^2)/((-2)*(1-rho2^2)*(sigeta^2))\n> >\n> >     return((exp(b31+b32+b33))/denom)\n> >  }\n> >\n> >  f5 <- function(z5) { # THIRD FUNCTION\n> >\n> >       b51 <- ((-y[i]+rho1*y[i-1]-muep)^2)/((-2)*(1-rho2^2)*sigep^2)\n> >       b52 <-\n> > (rho2*(-y[i]+rho1*y[i-1]-muep)*(z5))/((1-rho2^2)*sigep*sigeta)\n> >       b53 <- ((z5)^2)/((-2)*(1-rho2^2)*(sigeta^2))\n> >\n> >     return((exp(b51+b52+b53))/denom)\n> >  }\n> >\n> >\n> >  for (i in 2:n) {   # START FOR LOOP\n> >\n> >        upr1 <- (y[i]-rho1*y[i-1])\n> >        upr2 <- (y[i]-y[i-1]+delta)\n> >\n> >     # INTEGRATING THE THREE FUNCTIONS\n> >      out1 <- integrate(f1, lower = (-1)*upr1, upper = upr1)\n> >      out3 <- integrate(f3, lower = -Inf, upper = upr2)\n> >      out5 <- integrate(f5, lower= -Inf, upper = upr2)\n> >\n> >       pdf <- (out1$val + out3$val + out5$val)\n> >\n> >     lglik[i] <- log(pdf) # LOGLIKELIHOOD FOR OBSERVATION i\n> >\n> >     }               # END FOR LOOP\n> >\n> > return(-sum(lglik)) # RETURNING NEGATIVE OF THE LOGLIKELIHOOD\n> >                     # BECAUSE optim DOES MINIMIZATION BY DEFAULT\n> > }\n> >\n> > ***************** CODE ENDS *********************************\n> >\n> > Then I use:\n> >\n> >> urate <- read.table(\"~/Desktop/UNRATE1.txt\", header=TRUE) # DATA\n> >> alpha.start <- c(0.5, -1, -1, 0, 1, -1) # STARTING VALUES\n> >> out <- optim(alpha.start, LLK, gr=NULL, y=urate$y) # THIS GIVES NO\n> > ERROR\n> >\n> > or\n> >\n> >> out <- optim(alpha.start, LLK, gr=NULL, method=\"BFGS\", y=urate$y)\n> > Error in integrate(f3, lower = -Inf, upper = upr2) :\n> >        the integral is probably divergent\n> >\n> > ______________________________________________\n> > R-help@stat.math.ethz.ch mailing list\n> > https://stat.ethz.ch/mailman/listinfo/r-help\n> > PLEASE do read the posting guide\nhttp://www.R-project.org/posting-guide.html\n> > and provide commented, minimal, self-contained, reproducible code.\n> >\n>\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}