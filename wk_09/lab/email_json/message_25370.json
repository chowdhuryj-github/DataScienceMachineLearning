{"category": "ham", "to_address": "\"Adaikalavan Ramasamy\" <ramasamy@cancer.org.uk>", "from_address": "\"hadley wickham\" <h.wickham@gmail.com>", "subject": "Re: [R] Weighted least squares", "body": "On 5/8/07, Adaikalavan Ramasamy  wrote:\n> See below.\n>\n> hadley wickham wrote:\n> > Dear all,\n> >\n> > I'm struggling with weighted least squares, where something that I had\n> > assumed to be true appears not to be the case.  Take the following\n> > data set as an example:\n> >\n> > df <- data.frame(x = runif(100, 0, 100))\n> > df$y <- df$x + 1 + rnorm(100, sd=15)\n> >\n> > I had expected that:\n> >\n> > summary(lm(y ~ x, data=df, weights=rep(2, 100)))\n> > summary(lm(y ~ x, data=rbind(df,df)))\n>\n> You assign weights to different points according to some external\n> quality or reliability measure not number of times the data point was\n> measured.\n\nThat is one type of weighting - but what if I have already aggregated\ndata?  That is a perfectly valid type of weighting too.\n\n> Look at the estimates and standard error of the two models below:\n>\n>   coefficients( summary(f.w <- lm(y ~ x, data=df, weights=rep(2, 100))) )\n>               Estimate Std. Error   t value     Pr(>|t|)\n>   (Intercept) 1.940765 3.30348066  0.587491 5.582252e-01\n>   x           0.982610 0.05893262 16.673448 2.264258e-30\n>\n>   coefficients( summary( f.u <- lm(y ~ x, data=rbind(df,df) ) ) )\n>               Estimate Std. Error    t value     Pr(>|t|)\n>   (Intercept) 1.940765 2.32408609  0.8350659 4.046871e-01\n>   x           0.982610 0.04146066 23.6998165 1.012067e-59\n>\n> You can see that they have same coefficient estimates but the second one\n>   has smaller variances.\n>\n> The repeated values artificially deflates the variance and thus inflates\n> the precision. This is why you cannot treat replicate data as\n> independent observations.\n\nHardly artificially - I have repeated observations.\n\n> > would be equivalent, but they are not.  I suspect the difference is\n> > how the degrees of freedom is calculated - I had expected it to be\n> > sum(weights), but seems to be sum(weights > 0).  This seems\n> > unintuitive to me:\n> >\n> > summary(lm(y ~ x, data=df, weights=rep(c(0,2), each=50)))\n> > summary(lm(y ~ x, data=df, weights=rep(c(0.01,2), each=50)))\n> >\n> > What am I missing?  And what is the usual way to do a linear\n> > regression when you have aggregated data?\n>\n> I would be best to use the individual data points instead of aggregated\n> data as it allows you to estimate the within-group variations as well.\n\nThere is no within group variation - these are observations that occur\nwith same values many times in the dataset, so have been aggregated\ninto the a contingency table-like format.\n\n> If you had individual data points, you could try something as follows.\n> Please check the codes as I am no expert in the area of repeated measures.\n>\n>   x  <- runif(100, 0, 100)\n>   y1 <- x + rnorm(100, mean=1, sd=15)\n>   y2 <- y1 + rnorm(100, sd=5)\n>\n>   df <- data.frame( y=c(y1, y2),\n>                     x=c(x,x),\n>                     subject=factor(rep( paste(\"p\", 1:100, sep=\"\"), 2 ) ))\n>\n>   library(nlme)\n>   summary( lme( y ~ x, random = ~ 1 | subject, data=df ) )\n>\n> Try reading Pinheiro and Bates (http://tinyurl.com/yvvrr7) or related\n> material for more information. Hope this helps.\n\nI'm not interested in a mixed model, and I don't have individual data points.\n\nHadley\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}