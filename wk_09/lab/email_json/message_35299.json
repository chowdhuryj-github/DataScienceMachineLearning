{"category": "ham", "to_address": "Remigijus Lapinskas <remigijus.lapinskas@mif.vu.lt>", "from_address": "Petr PIKAL <petr.pikal@precheza.cz>", "subject": "[R] Odp:  reading a big file", "body": "Hi\n\nOne possibility is to use scan with combination of skip and nlines \nparameters in a body of for cycle and adding read portion to some suitable \nobject.\n\nRegards\n\nPetr\n\npetr.pikal@precheza.cz\n\nr-help-bounces@stat.math.ethz.ch napsal dne 23.05.2007 19:38:33:\n\n> Dear All,\n> \n> I am on WindowsXP with 512 MB of RAM, R 2.4.0, and I want to read in a\n> big file mln100.txt. The file is 390MB big, it contains a column of 100 \n> millions integers.\n> \n> > mln100=scan(\"mln100.txt\")\n> Error: cannot allocate vector of size 512000 Kb\n> In addition: Warning messages:\n> 1: Reached total allocation of 511Mb: see help(memory.size)\n> 2: Reached total allocation of 511Mb: see help(memory.size)\n> \n> In fact, I would be quite happy if I could read, say, every tenth \n> integer (line) of the file. Is it possible to do this?\n> \n> Cheers,\n> Rem\n> \n> ______________________________________________\n> R-help@stat.math.ethz.ch mailing list\n> https://stat.ethz.ch/mailman/listinfo/r-help\n> PLEASE do read the posting guide \nhttp://www.R-project.org/posting-guide.html\n> and provide commented, minimal, self-contained, reproducible code.\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}