{"category": "ham", "to_address": "Alan Zaslavsky <zaslavsk@hcp.med.harvard.edu>", "from_address": "Thomas Lumley <tlumley@u.washington.edu>", "subject": "Re: [R] Reasons to Use R", "body": "On Wed, 11 Apr 2007, Alan Zaslavsky wrote:\n> I have thought for a long time that a facility for efficient rowwise\n> calculations might be a valuable enhancement to S/R.  The storage of the\n> object would be handled by a database and there would have to be an\n> efficient interface for pulling a row (or small chunk of rows) out of the\n> database repeatedly; alternatively the operatons could be conducted inside\n> the database.  Basic operations of rowwise calculation and cumulation\n> (such as forming a column sum or a sum of outer-products) would be\n> written in an R-like syntax and translated into an efficient set of\n> operations that work through the database.  (Would be happy to share\n> some jejeune notes on this.)  However the main answer to thie problem\n> in the R world seems to have been Moore's Law.  Perhaps somebody could\n> tell us more about the S-Plus large objects library, or the work that\n> Spie Bates is doing on efficient calculations with large datasets.\n>\n\n\nI have been surprised to find how much you can get done in SQL, only transferring summudles of the data into R.  There is soon going to be an \nexperimental \"surveyNG\" package that works with survey data stored in a SQLite database without transferring the whole thing into R for most operations (and I \ncould get further if SQLite had the log() and exp() functions that most other SQL implementations for large databases provide). I'll be submitting a paper on \nthis to useR2007.\n\nThe approach of transferring blocks of data into R and using a database just as backing store will allow more general computation but will be less efficient \nthan performing the computation in the database, so a mixture of both is likely to be helpful.  Moore's Law will settle some issues, but there are problems where it is working to increase the size of datasets just as fast as it \nincreases computational power.\n\n\n     -thomas\n\nThomas Lumley\t\t\tAssoc. Professor, Biostatistics\ntlumley@u.washington.edu\tUniversity of Washington, Seattle\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}