{"category": "ham", "to_address": "Greg Snow <Greg.Snow@intermountainmail.org>", "from_address": "Prof Brian D Ripley <ripley@stats.ox.ac.uk>", "subject": "Re: [R] help comparing two median with R", "body": "On Wed, 18 Apr 2007, Greg Snow wrote:\n\n> For testing, the permutation test may be prefered to the bootstrap\n> (though the bootstrap could be used for a confidence interval).\n>\n> I remember in grad school doing a project on comparing the efficiency of\n> a permutation test on medians compared to the MannWhitney test, but I\n> don't remember the specifics of when each was better.  Do any of the\n> other participants in this discussion have any ideas on how the\n> permutation tests compare to what else has been discussed?\n>\n> The MannWhitney test is actually a special case of the permutation test,\n> but using the median permutation test is more intuitive to my mind.  The\n> permutation test is actually testing the null hypothesis that the 2\n> distributions are identical, but no assumptions about normality,\n> skewness, shift hypotheses, etc..  Though the efficiency of the test\n> statistic used would depend somewhat on the nature of the alternatives\n> of interest (imagine 2 distributions with the same mean, but different\n> medians, or same median, but different mean; a permutation test\n> comparing means or medians would differ in the 2 cases).\n\nI think the point is that one does not want to assume the two distributions \nare identical: the null hypothesis is that they have the same median but \npossibly different shapes (including spread).\n\nYou can set up bootstrap tests (see Davison & Hinkley, for example).\nCody Hamilton's CI is too crude: again see D&H or MASS for less crude \nalternatives.  However, bootstrapping a median has its own peculiarities: \nsee the example in MASS and references there, including to Sheather's book.\n\n\n> I'll have to try some simulations looking at a permutation test on\n> efron's dice.\n>\n> -- \n> Gregory (Greg) L. Snow Ph.D.\n> Statistical Data Center\n> Intermountain Healthcare\n> greg.snow@intermountainmail.org\n> (801) 408-8111\n>\n>\n>\n>> -----Original Message-----\n>> From: r-help-bounces@stat.math.ethz.ch\n>> [mailto:r-help-bounces@stat.math.ethz.ch] On Behalf Of\n>> Cody_Hamilton@edwards.com\n>> Sent: Wednesday, April 18, 2007 10:06 AM\n>> To: r-help@stat.math.ethz.ch\n>> Subject: Re: [R] help comparing two median with R\n>>\n>>\n>> Has anyone proposed using a bootstrap for Pedro's problem?\n>>\n>> What about taking a boostrap sample from x, a boostrap sample\n>> from y, take the difference in the medians for these two\n>> bootstrap samples, repeat the process 1,000 times and\n>> calculate the 95th percentiles of the 1,000 computed\n>> differences?  You would get a CI on the difference between\n>> the medians for these two groups, with which you could\n>> determine whether the difference was greater/less than zero.\n>> Too crude?\n>>\n>> Regards,\n>>    -Cody\n>>\n>>\n>>\n>>\n>>\n>>\n>>              Frank E Harrell\n>>\n>>              Jr\n>>\n>>              >           To\n>>              bilt.edu>                 Thomas Lumley\n>>\n>>              Sent by:\n>> \n>>              r-help-bounces@st\n>>           cc\n>>              at.math.ethz.ch\n>> r-help@stat.math.ethz.ch\n>>\n>>      Subject\n>>                                        Re: [R] help comparing\n>> two median\n>>              04/18/2007 05:02          with R\n>>\n>>              AM\n>>\n>>\n>>\n>>\n>>\n>>\n>>\n>>\n>>\n>>\n>>\n>>\n>>\n>>\n>>\n>> Thomas Lumley wrote:\n>>> On Tue, 17 Apr 2007, Frank E Harrell Jr wrote:\n>>>\n>>>> The points that Thomas and Brian have made are certainly\n>> correct, if\n>>>> one is truly interested in testing for differences in medians or\n>>>> means.  But the Wilcoxon test provides a valid test of x > y more\n>>>> generally.  The test is consonant with the Hodges-Lehmann\n>> estimator:\n>>>> the median of all possible differences between an X and a Y.\n>>>>\n>>>\n>>> Yes, but there is no ordering of distributions (taken one\n>> at a time)\n>>> that agrees with the Wilcoxon two-sample test, only\n>> orderings of pairs\n>>> of distributions.\n>>>\n>>> The Wilcoxon test provides a test of x>y if it is known a\n>> priori that\n>>> the two distributions are stochastically ordered, but not\n>> under weaker\n>>> assumptions.  Otherwise you can get x>y>z>x. This is in contrast to\n>>> the t-test, which orders distributions (by their mean)\n>> whether or not\n>>> they are stochastically ordered.\n>>>\n>>> Now, it is not unreasonable to say that the problems are\n>> unlikely to\n>>> occur very often and aren't worth worrying too much about. It does\n>>> imply that it cannot possibly be true that there is any\n>> summary of a\n>>> single distribution that the Wilcoxon test tests for (and\n>> the same is\n>>> true for other two-sample rank tests, eg the logrank test).\n>>>\n>>> I know Frank knows this, because I gave a talk on it at Vanderbilt,\n>>> but most people don't know it. (I thought for a long time that the\n>>> Wilcoxon rank-sum test was a test for the median pairwise\n>> mean, which\n>>> is actually the R-estimator corresponding to the\n>> *one*-sample Wilcoxon test).\n>>>\n>>>\n>>>     -thomas\n>>>\n>>\n>> Thanks for your note Thomas.  I do feel that the problems you\n>> have rightly listed occur infrequently and that often I only\n>> care about two groups.  Rank tests generally are good at\n>> relatives, not absolutes.  We have an efficient test\n>> (Wilcoxon) for relative shift but for estimating an absolute\n>> one-sample quantity (e.g., median) the nonparametric\n>> estimator is not very efficient.  Ironically there is an\n>> exact nonparametric confidence interval for the median\n>> (unrelated to Wilcoxon) but none exists for the mean.\n>>\n>> Cheers,\n>> Frank\n>> --\n>> Frank E Harrell Jr   Professor and Chair           School of Medicine\n>>                       Department of Biostatistics\n>> Vanderbilt University\n>>\n>> ______________________________________________\n>> R-help@stat.math.ethz.ch mailing list\n>> https://stat.ethz.ch/mailman/listinfo/r-help\n>> PLEASE do read the posting guide\n>> http://www.R-project.org/posting-guide.html\n>> and provide commented, minimal, self-contained, reproducible code.\n>>\n>> ______________________________________________\n>> R-help@stat.math.ethz.ch mailing list\n>> https://stat.ethz.ch/mailman/listinfo/r-help\n>> PLEASE do read the posting guide\n>> http://www.R-project.org/posting-guide.html\n>> and provide commented, minimal, self-contained, reproducible code.\n>>\n>\n> ______________________________________________\n> R-help@stat.math.ethz.ch mailing list\n> https://stat.ethz.ch/mailman/listinfo/r-help\n> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html\n> and provide commented, minimal, self-contained, reproducible code.\n>\n\n-- \nBrian D. Ripley,                  ripley@stats.ox.ac.uk\nProfessor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/\nUniversity of Oxford,             Tel:  +44 1865 272861 (self)\n1 South Parks Road,                     +44 1865 272866 (PA)\nOxford OX1 3TG, UK                Fax:  +44 1865 272595\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}