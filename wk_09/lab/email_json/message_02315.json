{"category": "ham", "to_address": "\"Greg Snow\" <Greg.Snow@intermountainmail.org>", "from_address": "\"Wensui Liu\" <liuwensui@gmail.com>", "subject": "Re: [R] Reasons to Use R", "body": "Greg,\nAs far as I understand, SAS is more efficient handling large data\nprobably than S+/R. Do you have any idea why?\n\nOn 4/10/07, Greg Snow  wrote:\n> > -----Original Message-----\n> > From: r-help-bounces@stat.math.ethz.ch\n> > [mailto:r-help-bounces@stat.math.ethz.ch] On Behalf Of\n> > Bi-Info (http://members.home.nl/bi-info)\n> > Sent: Monday, April 09, 2007 4:23 PM\n> > To: Gabor Grothendieck\n> > Cc: Lorenzo Isella; r-help@stat.math.ethz.ch\n> > Subject: Re: [R] Reasons to Use R\n>\n> [snip]\n>\n> > So what's the big deal about S using files instead of memory\n> > like R. I don't get the point. Isn't there enough swap space\n> > for S? (Who cares\n> > anyway: it works, isn't it?) Or are there any problems with S\n> > and large datasets? I don't get it. You use them, Greg. So\n> > you might discuss that issue.\n> >\n> > Wilfred\n> >\n> >\n>\n> This is my understanding of the issue (not anything official).\n>\n> If you use up all the memory while in R, then the OS will start swapping\n> memory to disk, but the OS does not know what parts of memory correspond\n> to which objects, so it is entirely possible that the chunk swapped to\n> disk contains parts of different data objects, so when you need one of\n> those objects again, everything needs to be swapped back in.  This is\n> very inefficient.\n>\n> S-PLUS occasionally runs into the same problem, but since it does some\n> of its own swapping to disk it can be more efficient by swapping single\n> data objects (data frames, etc.).  Also, since S-PLUS is already saving\n> everything to disk, it does not actually need to do a full swap, it can\n> just look and see that a particular data frame has not been used for a\n> while, know that it is already saved on the disk, and unload it from\n> memory without having to write it to disk first.\n>\n> The g.data package for R has some of this functionality of keeping data\n> on the disk until needed.\n>\n> The better approach for large data sets is to only have some of the data\n> in memory at a time and to automatically read just the parts that you\n> need.  So for big datasets it is recommended to have the actual data\n> stored in a database and use one of the database connection packages to\n> only read in the subset that you need.  The SQLiteDF package for R is\n> working on automating this process for R.  There are also the bigdata\n> module for S-PLUS and the biglm package for R have ways of doing some of\n> the common analyses using chunks of data at a time.  This idea is not\n> new.  There was a program in the late 1970s and 80s called Rummage by\n> Del Scott (I guess technically it still exists, I have a copy on a 5.25\"\n> floppy somewhere) that used the approach of specify the model you wanted\n> to fit first, then specify the data file.  Rummage would then figure out\n> which sufficient statistics were needed and read the data in chunks,\n> compute the sufficient statistics on the fly, and not keep more than a\n> couple of lines of the data in memory at once.  Unfortunately it did not\n> have much of a user interface, so when memory was cheap and datasets\n> only medium sized it did not compete well, I guess it was just a bit too\n> ahead of its time.\n>\n> Hope this helps,\n>\n>\n>\n> --\n> Gregory (Greg) L. Snow Ph.D.\n> Statistical Data Center\n> Intermountain Healthcare\n> greg.snow@intermountainmail.org\n> (801) 408-8111\n>\n> ______________________________________________\n> R-help@stat.math.ethz.ch mailing list\n> https://stat.ethz.ch/mailman/listinfo/r-help\n> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html\n> and provide commented, minimal, self-contained, reproducible code.\n>\n\n\n-- \nWenSui Liu\nA lousy statistician who happens to know a little programming\n(http://spaces.msn.com/statcompute/blog)\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}