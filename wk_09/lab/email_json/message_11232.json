{"category": "ham", "to_address": "Joshua Isom via RT <parrotbug-followup@parrotcode.org>", "from_address": "Andy Spieherty <spiehera@lafayette.edu>", "subject": "Re: [perl #42620] PGE 'Out of memory' panics.", "body": "On Fri, 20 Apr 2007, Joshua Isom via RT wrote:\n\n> \n> On Apr 20, 2007, at 9:18 AM, Andy Spieherty wrote:\n\n> As far as I know, --gc-debug doesn't actually do anything at all.  How \n> much ram do you have available when you start running the test?  You \n> might be doing a lot of swapping in and out of processes which is \n> slowing things down a lot.\n\nOh yes.  It's swapping like crazy.  Sorry I didn't mention that \nexplicitly.  (I figured it was obvious!)  The machine in question has \n128 MB of physical RAM.  Normally, in order to not be antisocial and bring \na shared machine to its knees, I set ulimit to restrict both the virtual \nmemory and the CPU time before running the parrot build and test scripts.\n\nSpecifically, I usually do something like:\n\n    ulimit -S -t 300   # Avoid runaway tests.\n    ulimit -S -v 98304 # 96 MB max:  Avoid runaway memory leaks.\n    ulimit -S -c 0     # Writing 96 MB core files wastes a lot of time.\n\nThat catches most of the \"Out of mem\" errors and kills most (but not\nall) of the hanging tests without excessively degrading performance for\nother processes running on the same system.\n\nThe main result is that the memory footprint of the pge tests appears to\ncontinuously grow.  This is reasonable because they run with -G, i.e.\ngarbage collection is turned off.  Oddly, if you turn on garbage\ncollection, the memory use grows *faster*.  Either way, I can't run the\ntests.\n\n-- \n    Andy Spieherty\t\tspiehera@lafayette.edu\n\n"}