{"category": "ham", "to_address": "r-help@stat.math.ethz.ch", "from_address": "\"ivo welch\" <ivowel@gmail.com>", "subject": "[R] Memory Experimentation: Rule of Thumb = 10-15 Times the Memory", "body": "dear R experts:\n\nI am of course no R experts, but use it regularly.  I thought I would\nshare some experimentation  with memory use.  I run a linux machine\nwith about 4GB of memory, and R 2.5.0.\n\nupon startup, gc() reports\n\n         used (Mb) gc trigger (Mb) max used (Mb)\nNcells 268755 14.4     407500 21.8   350000 18.7\nVcells 139137  1.1     786432  6.0   444750  3.4\n\nThis is my baseline.  linux 'top' reports 48MB as baseline.  This\nincludes some of my own routines that are always loaded.  Good..\n\n\nNext, I created a s.csv file with 22 variables and 500,000\nobservations, taking up an uncompressed disk space of 115MB.  The\nresulting object.size() after a read.csv() is 84,002,712 bytes (80MB).\n\n> s= read.csv(\"s.csv\");\n> object.size(s);\n\n[1] 84002712\n\n\nhere is where things get more interesting.  after the read.csv() is\nfinished, gc() reports\n\n           used (Mb) gc trigger  (Mb) max used  (Mb)\nNcells   270505 14.5    8349948 446.0 11268682 601.9\nVcells 10639515 81.2   34345544 262.1 42834692 326.9\n\nI was a big surprised by this---R had 928MB intermittent memory in\nuse.  More interestingly, this is also similar to what linux 'top'\nreports as memory use of the R process (919MB, probably 1024 vs. 1000\nB/MB), even after the read.csv() is finished and gc() has been run.\nNothing seems to have been released back to the OS.\n\nNow,\n\n> rm(s)\n> gc()\n         used (Mb) gc trigger  (Mb) max used  (Mb)\nNcells 270541 14.5    6679958 356.8 11268755 601.9\nVcells 139481  1.1   27476536 209.7 42807620 326.6\n\nlinux 'top' now reports 650MB of memory use (though R itself uses only\n15.6Mb).  My guess is that It leaves the trigger memory of 567MB plus\nthe base 48MB.\n\n\nThere are two interesting observations for me here:  first, to read a\n.csv file, I need to have at least 10-15 times as much memory as the\nfile that I want to read---a lot more than the factor of 3-4 that I\nhad expected.  The moral is that IF R can read a .csv file, one need\nnot worry too much about running into memory constraints lateron.  {R\nDevelopers---reducing read.csv's memory requirement a little would be\nnice.  of course, you have more than enough on your plate, already.}\n\nSecond, memory is not returned fully to the OS.  This is not\nnecessarily a bad thing, but good to know.\n\nHope this helps...\n\nSincerely,\n\n/iaw\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}