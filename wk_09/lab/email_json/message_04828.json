{"category": "ham", "to_address": "r-help@stat.math.ethz.ch", "from_address": "Simon Wood <s.wood@bath.ac.uk>", "subject": "Re: [R] Relative GCV - poisson and negbin GAMs (mgcv)", "body": "On Sunday 08 April 2007 05:57, Jordan T Watson wrote:\nSorry for the tardy reply - got filtered to the wrong place...\n\n> I am using gam in mgcv (1.3-22) and trying to use gcv to help with model\n> selection.  However, I'm a little confused by the process of assessing GCV\n> scores based on their magnitude (or on relative changes in magnitude).\n>\n> Differences in GCV scores often seem \"obvious\" with my poisson gams but\n> with negative binomial, the decision seems less clear.\n- This is not well  documented - sorry. The negative binomial is a special \ncase for mgcv::gam (see ?gam.neg.bin). To handle the extra parameter of the \nnegative binomial, smoothing parameter estimation *has* to be performed via \n`performance iteration' (see ?gam.method), which is not the default for any \nother family. Within the IRLS loop of the performance iteration an extra step \nis inserted which estimates the negative binomial parameter at each \niteration, in order to try and achieve a scale parameter estimate of 1 \n(see ?gam.neg.bin). However, trying to force the estimated scale parameter to \n1 will also force the GCV score used in performance iteration to be close to \n1 (at least for large samples), whatever model is fitted.... so comparison of \nGCV scores between different neg.bin models is unlikely to be very \ninformative. In addition small changes in GCV score are not meaningful when \ncomparing different models fitted by performance iteration, for any family \n(again see details section of ?gam.method). I think that AIC() would provide \na better basis for comparing alternative neg.bin GAMs: it's even more \napproximate than usual when used in this context, since the neg.bin parameter \nestimate is definitely not an MLE, but it will still give a much more \nmeaningful guide than comparison of GCV scores, in this case. \n\nFor other families none of these problems occur provided the default direct \n(`outer') smoothness selection method is used.\n\n> My data represent a similar pattern as below - where I see (seemingly)\n> drastic changes in GCV for the poisson with different model structures, but\n> the negative binomial often seems only to change in the second or third\n> decimal place for the same models.\n>\n> Is there a standard for how many decimals one should look at GCV, or am I\n> totally missing something (I'm quite new to this, as I'm sure is obvious). \n--- no there isn't. When using all other families (and the default `outer' \nfitting method) then simply choosing the lowest score is reasonable. For the \nnegative binomial, I think the answer is not to use the GCV score. \n\nbest,\nSimon\n\n\n>\n> Thanks in advance!\n> Jordan\n>\n>\n> library(mgcv)\n> set.seed(0)\n> n<-400\n> sig<-2\n> x0 <- runif(n, 0, 1)\n> x1 <- runif(n, 0, 1)\n> x2 <- runif(n, 0, 1)\n> x3 <- runif(n, 0, 1)\n> f0 <- function(x) 2 * sin(pi * x)\n> f1 <- function(x) exp(2 * x)\n> f2 <- function(x) 0.2*x^11*(10*(1-x))^6+10*(10*x)^3*(1-x)^10\n> f <- f0(x0) + f1(x1) + f2(x2)\n> g<-exp(f/4)\n> y<-rpois(rep(1,n),g)\n> summary(gam(y~s(x0)+s(x1)+s(x2)+s(x3),family=poisson,scale=-1))$gcv\n> summary(gam(y~x0+x1+x2+s(x3),family=poisson,scale=-1))$gcv\n> summary(gam(y~x0+x1+x2+x3,family=poisson,scale=-1))$gcv\n> summary(gam(y~s(x3),family=poisson,scale=-1))$gcv\n>\n> summary(gam(y~s(x0)+s(x1)+s(x2)+s(x3),family=negative.binomial(1)))$gcv\n> summary(gam(y~x0+x1+x2+s(x3),family=negative.binomial(1)))$gcv\n> summary(gam(y~x0+x1+x2+x3,family=negative.binomial(1)))$gcv\n> summary(gam(y~s(x3),family=negative.binomial(1)))$gcv\n>\n> Outputs from above:\n> > summary(gam(y~s(x0)+s(x1)+s(x2)+s(x3),family=poisson,scale=-1))$gcv\n>\n> [1] 1.218529\n>\n> > summary(gam(y~x0+x1+x2+s(x3),family=poisson,scale=-1))$gcv\n>\n> [1] 5.058014\n>\n> > summary(gam(y~x0+x1+x2+x3,family=poisson,scale=-1))$gcv\n>\n> [1] 4.954163\n>\n> > summary(gam(y~s(x3),family=poisson,scale=-1))$gcv\n>\n> [1] 8.286693\n>\n> > summary(gam(y~s(x0)+s(x1)+s(x2)+s(x3),family=negative.binomial(1)))$gcv\n>\n> [1] 1.047581\n>\n> > summary(gam(y~x0+x1+x2+s(x3),family=negative.binomial(1)))$gcv\n>\n> [1] 1.013617\n>\n> > summary(gam(y~x0+x1+x2+x3,family=negative.binomial(1)))$gcv\n>\n> [1] 1.012658\n>\n> > summary(gam(y~s(x3),family=negative.binomial(1)))$gcv\n>\n> [1] 1.005986\n>\n>\n> #######################################\n> Jordan Watson\n> School of Aquatic and Fishery Sciences\n> University of Washington\n> Seattle, WA\n>\n> ______________________________________________\n> R-help@stat.math.ethz.ch mailing list\n> https://stat.ethz.ch/mailman/listinfo/r-help\n> PLEASE do read the posting guide\n> http://www.R-project.org/posting-guide.html and provide commented, minimal,\n> self-contained, reproducible code.\n\n-- \n> Simon Wood, Mathematical Sciences, University of Bath, Bath, BA2 7AY UK\n> +44 1225 386603  www.maths.bath.ac.uk/~sw283\n\n______________________________________________\nR-help@stat.math.ethz.ch mailing list\nhttps://stat.ethz.ch/mailman/listinfo/r-help\nPLEASE do read the posting guide http://www.R-project.org/posting-guide.html\nand provide commented, minimal, self-contained, reproducible code.\n\n"}